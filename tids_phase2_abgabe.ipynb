{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datenerfassung\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "\n",
    "#Filepath\n",
    "white = '/home/dl4/dst/Winequality_White.xlsx'\n",
    "red = '/home/dl4/dst/Winequality_Red.xlsx'\n",
    "full_colored = '/home/dl4/dst/Winequality_full.xlsx'\n",
    "\n",
    "#Data with color\n",
    "df_listC = pd.read_excel(full_colored)\n",
    "\n",
    "df_listCnoNA = df_listC.dropna()\n",
    "#Clean quality from 99 and 17 values\n",
    "df_temp= df_listCnoNA[df_listCnoNA['quality']!=99]\n",
    "df_listCnoNAClean =df_temp[df_temp['quality']!=17]\n",
    "df_listCnoNAClean =df_listCnoNAClean[df_listCnoNAClean['pH']!=99.99] \n",
    "#df_listCnoNAClean -> Beide Weinsorten mit Farbenlabel ohne falsche pH und Quality Werte\n",
    "\n",
    "#Auftrennung in Datensatz Rotwein und Datensatz Weißwein\n",
    "df_red = df_listCnoNAClean.loc[df_listCnoNAClean[\"color\"] == \"red\"]\n",
    "df_white = df_listCnoNAClean.loc[df_listCnoNAClean[\"color\"] == \"white\"]\n",
    "\n",
    "df_red_org = df_listCnoNAClean.loc[df_listCnoNAClean[\"color\"] == \"red\"]\n",
    "df_white_org = df_listCnoNAClean.loc[df_listCnoNAClean[\"color\"] == \"white\"]\n",
    "\n",
    "#Label und ID Säule entfernen\n",
    "df_red = df_red.drop([\"color\", \"ID\"], axis=1)\n",
    "df_white = df_white.drop([\"color\", \"ID\"], axis=1).reset_index(drop=True)\n",
    "wine_list = [df_white, df_red]\n",
    "df_white\n",
    "\n",
    "\"\"\"Sebastian\"\"\"\n",
    "# Rot/Weißwein Dataset ohne \"ID\" und \"quality\"\n",
    "x_red = df_red_org.iloc[:,1:15]\n",
    "x_white = df_white_org.iloc[:,1:15]\n",
    "# Label-Daten (\"quality\")\n",
    "y_red = df_red_org.iloc[:,15]\n",
    "y_white = df_white_org.iloc[:,15]\n",
    "\n",
    "\n",
    "\n",
    "# \"flavanoids entfernen\"\n",
    "x_red = x_red.drop([\"flavanoids\",\"density\"], axis=1)\n",
    "x_white = x_white.drop(\"flavanoids\", axis=1)\n",
    "\"\"\"Sebastian\"\"\"\n",
    "\n",
    "#Train and test Data\n",
    "\n",
    "#x_train_red, x_test_red, y_train_red, y_test_red = train_test_split(df_listCnoNAClean.iloc[:,0:15], df_listCnoNAClean.iloc[:,15], test_size=0.2, random_state=1)\n",
    "x_train_red, x_test_red, y_train_red, y_test_red = train_test_split(df_red_org.iloc[:,1:15], df_red_org.iloc[:,15], test_size=0.2, random_state=1)\n",
    "x_train_white, x_test_white, y_train_white, y_test_white = train_test_split(df_white_org.iloc[:,1:15], df_white_org.iloc[:,15], test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Sebastian\"\"\"\n",
    "#Skalierung\n",
    "def min_max_scaler(x):\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaled = scaler.fit_transform(x)\n",
    "    df_scaled = pd.DataFrame(scaled, columns = x.columns)\n",
    "    \n",
    "    return df_scaled\n",
    "\n",
    "\n",
    "def robust_scaler(x):\n",
    "    \n",
    "    scaler = RobustScaler()\n",
    "    scaled = scaler.fit_transform(x)\n",
    "    df_scaled = pd.DataFrame(scaled, columns = x.columns)\n",
    "    \n",
    "    return df_scaled\n",
    "\n",
    "#MinMax Datensatz\n",
    "x_red_scaled = min_max_scaler(x_red)\n",
    "x_white_scaled = min_max_scaler(x_white)\n",
    "\n",
    "#Robust Datensatz\n",
    "#x_red_robust = min_max_scaler(x_red)\n",
    "#x_white_robust = min_max_scaler(x_white)\n",
    "x_red_robust = robust_scaler(x_red)\n",
    "x_white_robust = robust_scaler(x_white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4881 4637 4843 4636 4640\n",
      "1564 1485 1519 1485 1486\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'MCD als bestes abgeschnitten, wenn es darum geht Outlier effektiv zu entfernen --> jetzt schauen ob dieser auch für das Modell am Besten ist'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Sebastian\"\"\"\n",
    "\n",
    "#Outlier removal\n",
    "\n",
    "def outlier_removal(x_df, y_df):\n",
    "    #Konvertieren zu Numpy-Array für weitere Bearbeitung\n",
    "    x = x_df.to_numpy()\n",
    "    y = y_df.to_numpy()\n",
    "    \n",
    "    ######################\n",
    "    ###Isolation Forest###\n",
    "    ######################\n",
    "    iso_forest = IsolationForest(contamination=0.05, random_state=1)\n",
    "    outlier = iso_forest.fit_predict(x)\n",
    "    # Boolean Array mit Outlier = False\n",
    "    mask = outlier != -1\n",
    "    # Array mit Inliner\n",
    "    x_iso, y_iso = x[mask, :], y[mask]\n",
    "    # Dataframe erstellen\n",
    "    x_iso_df = pd.DataFrame(x_iso, columns=x_df.columns)\n",
    "    y_iso_df = pd.DataFrame(y_iso, columns=[\"quality\"])\n",
    "    \n",
    "    ##########################\n",
    "    ###Local Outlier Factor###\n",
    "    ##########################\n",
    "    outlier = LocalOutlierFactor().fit_predict(x)\n",
    "    mask = outlier != -1\n",
    "    #Array mit Inliner\n",
    "    x_lof, y_lof = x[mask, :], y[mask]\n",
    "    # Dataframe erstellen\n",
    "    x_lof_df = pd.DataFrame(x_lof, columns=x_df.columns)\n",
    "    y_lof_df = pd.DataFrame(y_lof, columns=[\"quality\"])\n",
    "    \n",
    "    ####################################\n",
    "    ###Minimum Covariance Determinant###\n",
    "    ####################################\n",
    "    outlier = EllipticEnvelope(contamination=0.05,random_state=1).fit_predict(x)\n",
    "    mask = outlier != -1\n",
    "    #Array mit Inliner\n",
    "    x_mcd, y_mcd = x[mask, :], y[mask]\n",
    "    # Dataframe erstellen\n",
    "    x_mcd_df = pd.DataFrame(x_mcd, columns=x_df.columns)\n",
    "    y_mcd_df = pd.DataFrame(y_mcd, columns=[\"quality\"])\n",
    "    \n",
    "    ###################\n",
    "    ###One-Class SVM###\n",
    "    ###################\n",
    "    outlier = OneClassSVM(nu=0.05).fit_predict(x)\n",
    "    mask = outlier != -1\n",
    "    #Array mit Inliner\n",
    "    x_ocs, y_ocs = x[mask, :], y[mask]\n",
    "    # Dataframe erstellen\n",
    "    x_ocs_df = pd.DataFrame(x_ocs, columns=x_df.columns)\n",
    "    y_ocs_df = pd.DataFrame(y_ocs, columns=[\"quality\"])\n",
    "    \n",
    "    \n",
    "    \n",
    "    return (x_iso_df, y_iso_df), (x_lof_df, y_lof_df), (x_mcd_df, y_mcd_df), (x_ocs_df, y_ocs_df)\n",
    "\n",
    "# Erstellt zu jeder Outlier Detection Methode ein Datensatz\n",
    "iso, lof, mcd, ocs = outlier_removal(x_red_scaled, y_red)\n",
    "\n",
    "x_red_iso, y_red_iso = iso\n",
    "x_red_lof, y_red_lof = lof\n",
    "x_red_mcd, y_red_mcd = mcd\n",
    "x_red_ocs, y_red_ocs = ocs\n",
    "\n",
    "iso, lof, mcd, ocs = outlier_removal(x_white_scaled, y_white)\n",
    "\n",
    "x_white_iso, y_white_iso = iso\n",
    "x_white_lof, y_white_lof = lof\n",
    "x_white_mcd, y_white_mcd = mcd\n",
    "x_white_ocs, y_white_ocs = ocs\n",
    "\n",
    "print(len(x_white), len(x_white_iso), len(x_white_lof), len(x_white_mcd), len(x_white_ocs))\n",
    "print(len(x_red), len(x_red_iso), len(x_red_lof), len(x_red_mcd), len(x_red_ocs))\n",
    "\n",
    "\n",
    "\"\"\"MCD als bestes abgeschnitten, wenn es darum geht Outlier effektiv zu entfernen --> jetzt schauen ob dieser auch für das Modell am Besten ist\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Sebastian\"\"\"\n",
    "# Skalierung des MCD Outlier Datensatzes\n",
    "#Skaliert den erstellten Datensatz ohne Outlier wieder auf Range 0 bis 1\n",
    "x_red_mcd_scaled = min_max_scaler(x_red_mcd)\n",
    "x_white_mcd_scaled = min_max_scaler(x_white_mcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>lightness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.252006</td>\n",
       "      <td>0.116682</td>\n",
       "      <td>0.335639</td>\n",
       "      <td>1.938946</td>\n",
       "      <td>0.274724</td>\n",
       "      <td>0.688266</td>\n",
       "      <td>0.795737</td>\n",
       "      <td>2.129781</td>\n",
       "      <td>-1.334455</td>\n",
       "      <td>-0.119008</td>\n",
       "      <td>-0.237138</td>\n",
       "      <td>-1.639249</td>\n",
       "      <td>1.924533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.632269</td>\n",
       "      <td>0.450011</td>\n",
       "      <td>0.157092</td>\n",
       "      <td>-1.099651</td>\n",
       "      <td>0.627133</td>\n",
       "      <td>-1.441453</td>\n",
       "      <td>-0.092160</td>\n",
       "      <td>0.074283</td>\n",
       "      <td>0.776307</td>\n",
       "      <td>0.229664</td>\n",
       "      <td>0.156505</td>\n",
       "      <td>-0.827961</td>\n",
       "      <td>0.280751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.474699</td>\n",
       "      <td>0.231848</td>\n",
       "      <td>0.679177</td>\n",
       "      <td>0.346924</td>\n",
       "      <td>0.712304</td>\n",
       "      <td>-0.239407</td>\n",
       "      <td>-0.988266</td>\n",
       "      <td>0.441462</td>\n",
       "      <td>0.525985</td>\n",
       "      <td>0.229664</td>\n",
       "      <td>-0.342386</td>\n",
       "      <td>-0.239099</td>\n",
       "      <td>0.280751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.488397</td>\n",
       "      <td>-0.389542</td>\n",
       "      <td>-0.026241</td>\n",
       "      <td>0.644940</td>\n",
       "      <td>1.355198</td>\n",
       "      <td>0.800250</td>\n",
       "      <td>1.146687</td>\n",
       "      <td>0.602054</td>\n",
       "      <td>0.067199</td>\n",
       "      <td>0.125484</td>\n",
       "      <td>-0.793967</td>\n",
       "      <td>-0.425922</td>\n",
       "      <td>1.093013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.488397</td>\n",
       "      <td>-0.389542</td>\n",
       "      <td>-0.026241</td>\n",
       "      <td>0.644940</td>\n",
       "      <td>1.355198</td>\n",
       "      <td>0.800250</td>\n",
       "      <td>1.146687</td>\n",
       "      <td>0.602054</td>\n",
       "      <td>0.067199</td>\n",
       "      <td>0.090679</td>\n",
       "      <td>-0.793967</td>\n",
       "      <td>-0.425922</td>\n",
       "      <td>-0.511005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4631</th>\n",
       "      <td>-0.766452</td>\n",
       "      <td>-0.673444</td>\n",
       "      <td>-0.310691</td>\n",
       "      <td>-1.099651</td>\n",
       "      <td>-0.292103</td>\n",
       "      <td>-0.660724</td>\n",
       "      <td>-1.123275</td>\n",
       "      <td>-0.983570</td>\n",
       "      <td>0.589341</td>\n",
       "      <td>-0.829327</td>\n",
       "      <td>0.248559</td>\n",
       "      <td>0.649413</td>\n",
       "      <td>-0.511005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4632</th>\n",
       "      <td>-0.241907</td>\n",
       "      <td>0.653189</td>\n",
       "      <td>0.335639</td>\n",
       "      <td>0.556826</td>\n",
       "      <td>0.453326</td>\n",
       "      <td>1.325068</td>\n",
       "      <td>0.750967</td>\n",
       "      <td>0.376151</td>\n",
       "      <td>-0.207758</td>\n",
       "      <td>1.219779</td>\n",
       "      <td>-0.134726</td>\n",
       "      <td>-0.723678</td>\n",
       "      <td>1.093013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4633</th>\n",
       "      <td>-0.370049</td>\n",
       "      <td>-0.255683</td>\n",
       "      <td>-1.350945</td>\n",
       "      <td>-1.249771</td>\n",
       "      <td>-0.097749</td>\n",
       "      <td>-0.239407</td>\n",
       "      <td>-0.619888</td>\n",
       "      <td>-0.445514</td>\n",
       "      <td>-1.415584</td>\n",
       "      <td>1.421113</td>\n",
       "      <td>-0.134726</td>\n",
       "      <td>-0.934923</td>\n",
       "      <td>1.093013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4634</th>\n",
       "      <td>-1.768471</td>\n",
       "      <td>0.342893</td>\n",
       "      <td>-0.214576</td>\n",
       "      <td>-1.288500</td>\n",
       "      <td>-2.208815</td>\n",
       "      <td>-0.960392</td>\n",
       "      <td>-0.645744</td>\n",
       "      <td>-2.038189</td>\n",
       "      <td>1.018641</td>\n",
       "      <td>-0.901400</td>\n",
       "      <td>-1.039835</td>\n",
       "      <td>1.631095</td>\n",
       "      <td>-2.026893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4635</th>\n",
       "      <td>-1.041236</td>\n",
       "      <td>-0.673444</td>\n",
       "      <td>0.509603</td>\n",
       "      <td>-1.407697</td>\n",
       "      <td>-2.471636</td>\n",
       "      <td>-0.808573</td>\n",
       "      <td>-0.961487</td>\n",
       "      <td>-1.711499</td>\n",
       "      <td>0.525985</td>\n",
       "      <td>-1.448725</td>\n",
       "      <td>-1.871669</td>\n",
       "      <td>1.053472</td>\n",
       "      <td>-1.280798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4636 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0          0.252006          0.116682     0.335639        1.938946   0.274724   \n",
       "1         -0.632269          0.450011     0.157092       -1.099651   0.627133   \n",
       "2          1.474699          0.231848     0.679177        0.346924   0.712304   \n",
       "3          0.488397         -0.389542    -0.026241        0.644940   1.355198   \n",
       "4          0.488397         -0.389542    -0.026241        0.644940   1.355198   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4631      -0.766452         -0.673444    -0.310691       -1.099651  -0.292103   \n",
       "4632      -0.241907          0.653189     0.335639        0.556826   0.453326   \n",
       "4633      -0.370049         -0.255683    -1.350945       -1.249771  -0.097749   \n",
       "4634      -1.768471          0.342893    -0.214576       -1.288500  -2.208815   \n",
       "4635      -1.041236         -0.673444     0.509603       -1.407697  -2.471636   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide   density        pH  \\\n",
       "0                0.688266              0.795737  2.129781 -1.334455   \n",
       "1               -1.441453             -0.092160  0.074283  0.776307   \n",
       "2               -0.239407             -0.988266  0.441462  0.525985   \n",
       "3                0.800250              1.146687  0.602054  0.067199   \n",
       "4                0.800250              1.146687  0.602054  0.067199   \n",
       "...                   ...                   ...       ...       ...   \n",
       "4631            -0.660724             -1.123275 -0.983570  0.589341   \n",
       "4632             1.325068              0.750967  0.376151 -0.207758   \n",
       "4633            -0.239407             -0.619888 -0.445514 -1.415584   \n",
       "4634            -0.960392             -0.645744 -2.038189  1.018641   \n",
       "4635            -0.808573             -0.961487 -1.711499  0.525985   \n",
       "\n",
       "      sulphates  magnesium   alcohol  lightness  \n",
       "0     -0.119008  -0.237138 -1.639249   1.924533  \n",
       "1      0.229664   0.156505 -0.827961   0.280751  \n",
       "2      0.229664  -0.342386 -0.239099   0.280751  \n",
       "3      0.125484  -0.793967 -0.425922   1.093013  \n",
       "4      0.090679  -0.793967 -0.425922  -0.511005  \n",
       "...         ...        ...       ...        ...  \n",
       "4631  -0.829327   0.248559  0.649413  -0.511005  \n",
       "4632   1.219779  -0.134726 -0.723678   1.093013  \n",
       "4633   1.421113  -0.134726 -0.934923   1.093013  \n",
       "4634  -0.901400  -1.039835  1.631095  -2.026893  \n",
       "4635  -1.448725  -1.871669  1.053472  -1.280798  \n",
       "\n",
       "[4636 rows x 13 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Sebastian\"\"\"\n",
    "# Normalisieren\n",
    "#Transformiert Datensatz zu einer perfekten Gauss Kurve\n",
    "\n",
    "#PowerTransformer\n",
    "def power_transformer(x):\n",
    "    transformer = PowerTransformer()\n",
    "    transformed = transformer.fit_transform(x)\n",
    "    df_transformed = pd.DataFrame(transformed, columns = x.columns)\n",
    "    return df_transformed\n",
    "\n",
    "x_red_pt = power_transformer(x_red)\n",
    "x_red_pt_scaled = min_max_scaler(x_red_pt)\n",
    "x_white_pt = power_transformer(x_white)\n",
    "\n",
    "x_red_mcd_scaled_pt = power_transformer(x_red_mcd_scaled)\n",
    "x_white_mcd_scaled_pt = power_transformer(x_white_mcd_scaled)\n",
    "x_white_mcd_scaled_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       " 0          0.252006          0.116682     0.335639        1.938946   0.274724   \n",
       " 1         -0.632269          0.450011     0.157092       -1.099651   0.627133   \n",
       " 2          1.474699          0.231848     0.679177        0.346924   0.712304   \n",
       " 3          0.488397         -0.389542    -0.026241        0.644940   1.355198   \n",
       " 4          0.488397         -0.389542    -0.026241        0.644940   1.355198   \n",
       " ...             ...               ...          ...             ...        ...   \n",
       " 4631      -0.766452         -0.673444    -0.310691       -1.099651  -0.292103   \n",
       " 4632      -0.241907          0.653189     0.335639        0.556826   0.453326   \n",
       " 4633      -0.370049         -0.255683    -1.350945       -1.249771  -0.097749   \n",
       " 4634      -1.768471          0.342893    -0.214576       -1.288500  -2.208815   \n",
       " 4635      -1.041236         -0.673444     0.509603       -1.407697  -2.471636   \n",
       " \n",
       "       free sulfur dioxide  total sulfur dioxide   density        pH  \\\n",
       " 0                0.688266              0.795737  2.129781 -1.334455   \n",
       " 1               -1.441453             -0.092160  0.074283  0.776307   \n",
       " 2               -0.239407             -0.988266  0.441462  0.525985   \n",
       " 3                0.800250              1.146687  0.602054  0.067199   \n",
       " 4                0.800250              1.146687  0.602054  0.067199   \n",
       " ...                   ...                   ...       ...       ...   \n",
       " 4631            -0.660724             -1.123275 -0.983570  0.589341   \n",
       " 4632             1.325068              0.750967  0.376151 -0.207758   \n",
       " 4633            -0.239407             -0.619888 -0.445514 -1.415584   \n",
       " 4634            -0.960392             -0.645744 -2.038189  1.018641   \n",
       " 4635            -0.808573             -0.961487 -1.711499  0.525985   \n",
       " \n",
       "       sulphates  magnesium   alcohol  lightness  \n",
       " 0     -0.119008  -0.237138 -1.639249   1.924533  \n",
       " 1      0.229664   0.156505 -0.827961   0.280751  \n",
       " 2      0.229664  -0.342386 -0.239099   0.280751  \n",
       " 3      0.125484  -0.793967 -0.425922   1.093013  \n",
       " 4      0.090679  -0.793967 -0.425922  -0.511005  \n",
       " ...         ...        ...       ...        ...  \n",
       " 4631  -0.829327   0.248559  0.649413  -0.511005  \n",
       " 4632   1.219779  -0.134726 -0.723678   1.093013  \n",
       " 4633   1.421113  -0.134726 -0.934923   1.093013  \n",
       " 4634  -0.901400  -1.039835  1.631095  -2.026893  \n",
       " 4635  -1.448725  -1.871669  1.053472  -1.280798  \n",
       " \n",
       " [4636 rows x 13 columns],\n",
       "       quality\n",
       " 0           6\n",
       " 1           6\n",
       " 2           6\n",
       " 3           6\n",
       " 4           6\n",
       " ...       ...\n",
       " 4631        6\n",
       " 4632        5\n",
       " 4633        6\n",
       " 4634        7\n",
       " 4635        6\n",
       " \n",
       " [4636 rows x 1 columns])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Sebastian\"\"\"\n",
    "# Datensätze generieren // Datensatzübersicht\n",
    "\n",
    "############################\n",
    "#### Normale Datensätze ####\n",
    "############################\n",
    "x_red, y_red\n",
    "x_white, y_white\n",
    "\n",
    "##############################\n",
    "#### Skalierte Datensätze ####\n",
    "##############################\n",
    "# Normal\n",
    "x_red_scaled, y_red\n",
    "x_white_scaled, y_white\n",
    "\n",
    "# Ohne Outlier (MCD)\n",
    "x_red_mcd_scaled, y_red_mcd\n",
    "x_white_mcd_scaled, y_white_mcd\n",
    "\n",
    "###############################\n",
    "#### Gefilterte Datensätze ####\n",
    "###############################\n",
    "\"\"\"Alle Outlier Datensätze arbeiten mit dem Skalierten [0-1] Datensatz, MCD (Beste Outlier Reduction) wurde daraufhin nochmals auf [0-1] skaliert damit man mit diesem weiterarbeiten kann\"\"\"\n",
    "\n",
    "# Isolation Forest\n",
    "x_red_iso, y_red_iso\n",
    "x_white_iso, y_white_iso\n",
    "\n",
    "# Local Outlier Factor\n",
    "x_red_lof, y_red_lof\n",
    "x_white_lof, y_white_lof\n",
    "\n",
    "# Minimum Covariance Determinant\n",
    "x_red_mcd, y_red_mcd\n",
    "x_white_mcd, y_white_mcd\n",
    "# Minimum Covariance Determinant (Skaliert)\n",
    "x_red_mcd_scaled, y_red_mcd\n",
    "x_white_mcd_scaled, y_white_mcd\n",
    "\n",
    "# One-Class SVM\n",
    "x_red_ocs, y_red_ocs\n",
    "x_white_ocs, y_white_ocs\n",
    "\n",
    "##############################\n",
    "#### Normierte Datensätze ####\n",
    "##############################\n",
    "\n",
    "### PowerTransformer ###\n",
    "#Normaler Datensatz\n",
    "x_red_pt, y_red\n",
    "#Normaler Datensatz (wieder auf [0-1] skaliert, macht wahrscheinlich keinen großen Unterschied, aber kann man mal experimentieren)\n",
    "x_red_pt_scaled, y_red\n",
    "\n",
    "# Ohne Outlier (MCD)\n",
    "x_red_mcd_scaled, y_red_mcd\n",
    "x_white_mcd_scaled_pt, y_white_mcd\n",
    "\n",
    "\n",
    "################################\n",
    "#### Selektierte Datensätze ####\n",
    "################################\n",
    "\n",
    "\n",
    "#Zu Untersuchen. Datensatz ohne:\n",
    "# Density\n",
    "# Lightness\n",
    "# pH bei Rotwein (wenn sklaierter Datensatz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training and Testdata\n",
    "def print_trainsplit(x_train, x_test):\n",
    "    print(\"\\n\",\"--------------Training / Testdata Stats--------------\")\n",
    "    total=x_train.shape[0]+x_test.shape[0]\n",
    "    print(\"Overall number of examples in wine data set\",total)\n",
    "    print(\"Training examples: \",x_train.shape[0],\", test examples: \",x_test.shape[0])\n",
    "    print(\"Calculated percentage of training examples: \",x_train.shape[0]/total*100,\"%\")\n",
    "    print(\"Calculated percentage of test examples: \",x_test.shape[0]/total*100,\"%\")\n",
    "    \n",
    "def make_trainsplit(x,y, split=0.2): #Macht Split fuer Trainings- und Testdaten. Default Split = 0.2 (Testdatenanteil)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=split, random_state=1)\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red Wine default Scores:  0.32613045646973593 (Lin.Regr.)  0.5846645367412141 (Log.Regr.)\n",
      "White Wine default Scores:  0.23918273507862386 (Lin.Regr.)  0.4790174002047083 (Log.Regr.)\n",
      "PowerTransformer Scores:  0.33866104708358913 (Lin.Regr.)  0.5910543130990416 (Log.Regr.)\n",
      "PowerTransformer([0-1] skaliert) Scores:  0.33866104708358913 (Lin.Regr.)  0.5718849840255591 (Log.Regr.)\n",
      "Minimum Covariance Determinant (Skaliert) Scores:  0.4430299478126545 (Lin.Regr.)  0.6195286195286195 (Log.Regr.)\n"
     ]
    }
   ],
   "source": [
    "#Regressionsanalyse\n",
    "#Linear Regression\n",
    "def make_regression(x_train, y_train, x_test, y_test):\n",
    "    from sklearn import linear_model\n",
    "    \n",
    "    import numpy as np\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn import datasets\n",
    "    from sklearn import svm\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    ##print(\"--------------LinearRegression--------------\")\n",
    "    reg = linear_model.LinearRegression()\n",
    "    reg.fit(x_train,y_train)\n",
    "    #print(\"Regression coefficients: \",reg.coef_)\n",
    "    f_pre= reg.predict(x_test)\n",
    "    #Return the coefficient of determination R^2 of the prediction.\n",
    "    ##print(\"R^2 value of the model: \",reg.score(x_test,y_test))\n",
    "    \n",
    "    #Logistic Regression\n",
    "    ##print(\"--------------LogisticRegression--------------\")\n",
    "    clf = LogisticRegression(random_state=1, solver=\"liblinear\").fit(x_train, y_train)\n",
    "    y_val_pred = clf.predict(x_test)\n",
    "    ##print(\"Score Logistic Regression: \", clf.score(x_test,y_test))\n",
    "    ##print(\"\\n\")\n",
    "    reg = reg.score(x_test,y_test)\n",
    "    log = clf.score(x_test,y_test)\n",
    "    return reg, log\n",
    "    \n",
    "reg,log = make_regression(x_train_red, y_train_red, x_test_red, y_test_red)\n",
    "print(\"Red Wine default Scores: \",reg,\"(Lin.Regr.) \", log, \"(Log.Regr.)\")\n",
    "reg,log =make_regression(x_train_white, y_train_white, x_test_white, y_test_white)\n",
    "print(\"White Wine default Scores: \",reg,\"(Lin.Regr.) \", log, \"(Log.Regr.)\")\n",
    "\n",
    "x_train_red3, x_test_red3, y_train_red3, y_test_red3 = train_test_split(x_red_pt, y_red, test_size=0.2, random_state=1)\n",
    "reg,log =make_regression(x_train_red3, y_train_red3, x_test_red3, y_test_red3)\n",
    "print(\"PowerTransformer Scores: \",reg,\"(Lin.Regr.) \", log, \"(Log.Regr.)\")\n",
    "\n",
    "x_train_red4, x_test_red4, y_train_red4, y_test_red4 = train_test_split(x_red_pt_scaled, y_red, test_size=0.2, random_state=1)\n",
    "reg,log =make_regression(x_train_red4, y_train_red4, x_test_red4, y_test_red4)\n",
    "print(\"PowerTransformer([0-1] skaliert) Scores: \",reg,\"(Lin.Regr.) \", log, \"(Log.Regr.)\")\n",
    "\n",
    "x_train_red5, x_test_red5, y_train_red5, y_test_red5 = train_test_split(x_red_mcd_scaled,y_red_mcd, test_size=0.2, random_state=1)\n",
    "reg,log =make_regression(x_train_red5, y_train_red5, x_test_red5, y_test_red5)\n",
    "print(\"Minimum Covariance Determinant (Skaliert) Scores: \",reg,\"(Lin.Regr.) \", log, \"(Log.Regr.)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@@@@@@@@@@@@@@@@@@@@@---Red Wine---@@@@@@@@@@@@@@@@@@@@@@@\n",
      "\n",
      " --------------Training / Testdata Stats--------------\n",
      "Overall number of examples in wine data set 1564\n",
      "Training examples:  1251 , test examples:  313\n",
      "Calculated percentage of training examples:  79.98721227621483 %\n",
      "Calculated percentage of test examples:  20.012787723785166 %\n",
      "\n",
      "\n",
      "Lin. Regression Score before:  0.32613045646973593\n",
      "Log. Regression Score before:  0.5846645367412141\n",
      "\n",
      "\n",
      "--------------Outliers: Isolation Forests--------------\n",
      "[[ 6.4    0.8    0.    ...  0.93  11.6    0.09 ]\n",
      " [ 8.     0.43   0.36  ...  0.37   9.4    0.113]\n",
      " [ 7.9    0.52   0.26  ...  0.24   9.5    0.108]\n",
      " ...\n",
      " [ 5.     0.4    0.5   ...  0.25  13.6    0.08 ]\n",
      " [ 8.9    0.64   0.37  ...  0.34   9.3    0.11 ]\n",
      " [ 7.9    0.3    0.68  ...  0.03  12.3    0.085]]\n",
      "[False  True  True ... False  True False]\n",
      "Inliers:  1126 Outliers 125\n",
      "Lin. Regression Score:  0.32876818611826364 Diff:  0.002637729648527709 ( 0.808795865642338 % )\n",
      "Log. Regression Score:  0.5910543130990416 Diff:  0.006389776357827448 ( 1.0928961748633832 % )\n",
      "--------------Outliers: Minimum Covariance Determinant--------------\n",
      "Inliers:  1125 Outliers 126\n",
      "Lin. Regression Score:  0.2883653598938739 Diff:  -0.03776509657586202 ( -11.579751546254782 % )\n",
      "Log. Regression Score:  0.5814696485623003 Diff:  -0.0031948881789137795 ( -0.546448087431701 % )\n",
      "--------------Outliers: Local Outlier Factor--------------\n",
      "Inliers:  1225 Outliers 26\n",
      "Lin. Regression Score:  0.3240078409520286 Diff:  -0.002122615517707316 ( -0.6508486023304877 % )\n",
      "Log. Regression Score:  0.5846645367412141 Diff:  0.0 ( 0.0 % )\n",
      "--------------Outliers: One-Class SVM--------------\n",
      "Inliers:  1240 Outliers 11\n",
      "Lin. Regression Score:  0.32710965121907 Diff:  0.0009791947493340558 ( 0.3002463369823059 % )\n",
      "Log. Regression Score:  0.5846645367412141 Diff:  0.0 ( 0.0 % )\n",
      "@@@@@@@@@@@@@@@@@@@@@@---White Wine---@@@@@@@@@@@@@@@@@@@@@@@\n",
      "\n",
      " --------------Training / Testdata Stats--------------\n",
      "Overall number of examples in wine data set 4881\n",
      "Training examples:  3904 , test examples:  977\n",
      "Calculated percentage of training examples:  79.98360991600082 %\n",
      "Calculated percentage of test examples:  20.01639008399918 %\n",
      "\n",
      "\n",
      "Lin. Regression Score before:  0.23918273507862386\n",
      "Log. Regression Score before:  0.4790174002047083\n",
      "\n",
      "\n",
      "--------------Outliers: Isolation Forests--------------\n",
      "[[ 7.1   0.32  0.3  ...  0.49 10.2   0.11]\n",
      " [ 6.6   0.34  0.25 ...  0.71 12.6   0.08]\n",
      " [ 7.    0.24  0.25 ...  0.42 11.    0.11]\n",
      " ...\n",
      " [ 7.7   0.32  0.62 ...  0.44  8.9   0.12]\n",
      " [ 6.    0.26  0.29 ...  0.39 12.8   0.09]\n",
      " [ 7.3   0.32  0.23 ...  0.46  8.7   0.12]]\n",
      "[ True  True  True ...  True  True  True]\n",
      "Inliers:  3513 Outliers 391\n",
      "Lin. Regression Score:  0.23983538725043918 Diff:  0.0006526521718153155 ( 0.27286759288908397 % )\n",
      "Log. Regression Score:  0.4790174002047083 Diff:  0.0 ( 0.0 % )\n",
      "--------------Outliers: Minimum Covariance Determinant--------------\n",
      "Inliers:  3513 Outliers 391\n",
      "Lin. Regression Score:  0.23943518035120104 Diff:  0.0002524452725771731 ( 0.10554493930934837 % )\n",
      "Log. Regression Score:  0.4820880245649949 Diff:  0.0030706243602866 ( 0.6410256410256429 % )\n",
      "--------------Outliers: Local Outlier Factor--------------\n",
      "Inliers:  3840 Outliers 64\n",
      "Lin. Regression Score:  0.2355558998445092 Diff:  -0.003626835234114667 ( -1.5163449121536543 % )\n",
      "Log. Regression Score:  0.4820880245649949 Diff:  0.0030706243602866 ( 0.6410256410256429 % )\n",
      "--------------Outliers: One-Class SVM--------------\n",
      "Inliers:  3864 Outliers 40\n",
      "Lin. Regression Score:  0.23800994381935947 Diff:  -0.001172791259264394 ( -0.49033274031207796 % )\n",
      "Log. Regression Score:  0.4749232343909928 Diff:  -0.004094165813715467 ( -0.854700854700857 % )\n"
     ]
    }
   ],
   "source": [
    "#Outlier detection/deletion\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "def make_outliers(x_train, y_train, x_test, y_test):\n",
    "    reg_o, log_o = make_regression(x_train, y_train, x_test, y_test)\n",
    "    print(\"\\n\")\n",
    "    print(\"Lin. Regression Score before: \", reg_o)\n",
    "    print(\"Log. Regression Score before: \", log_o)\n",
    "    #Outliers: Isolation Forests\n",
    "    print(\"\\n\")\n",
    "    print(\"--------------Outliers: Isolation Forests--------------\")\n",
    "    iso = IsolationForest(contamination=0.1, random_state=1)\n",
    "    y_out = iso.fit_predict(x_train)\n",
    "    mask = y_out != -1\n",
    "    print(x_train)\n",
    "    print(mask)\n",
    "    X_train_inl, y_train_inl = x_train[mask, :], y_train[mask]\n",
    "    print(\"Inliers: \",X_train_inl.shape[0],\"Outliers\",x_train.shape[0]-X_train_inl.shape[0])\n",
    "    reg, log = make_regression(X_train_inl, y_train_inl, x_test, y_test)\n",
    "    print(\"Lin. Regression Score: \", reg, \"Diff: \", reg-reg_o, \"(\",((reg-reg_o)/reg_o)*100,\"% )\")\n",
    "    print(\"Log. Regression Score: \", log, \"Diff: \", log-log_o, \"(\",((log-log_o)/log_o)*100,\"% )\")   \n",
    "    \n",
    "    #Outliers: Minimum Covariance Determinant\n",
    "    print(\"--------------Outliers: Minimum Covariance Determinant--------------\")\n",
    "    y_out = EllipticEnvelope(contamination=0.1,random_state=1).fit_predict(x_train)\n",
    "    mask = y_out != -1\n",
    "    X_train_inl2, y_train_inl2 = x_train[mask, :], y_train[mask]\n",
    "    print(\"Inliers: \",X_train_inl2.shape[0],\"Outliers\",x_train.shape[0]-X_train_inl2.shape[0])\n",
    "    reg, log = make_regression(X_train_inl2, y_train_inl2, x_test, y_test)\n",
    "    print(\"Lin. Regression Score: \", reg, \"Diff: \", reg-reg_o, \"(\",((reg-reg_o)/reg_o)*100,\"% )\")\n",
    "    print(\"Log. Regression Score: \", log, \"Diff: \", log-log_o, \"(\",((log-log_o)/log_o)*100,\"% )\")    \n",
    "    \n",
    "    #Outliers: Local Outlier Factor\n",
    "    print(\"--------------Outliers: Local Outlier Factor--------------\")\n",
    "    y_out = LocalOutlierFactor().fit_predict(x_train)\n",
    "    mask = y_out != -1\n",
    "    X_train_inl3, y_train_inl3 = x_train[mask, :], y_train[mask]\n",
    "    print(\"Inliers: \",X_train_inl3.shape[0],\"Outliers\",x_train.shape[0]-X_train_inl3.shape[0])\n",
    "    reg, log = make_regression(X_train_inl3, y_train_inl3, x_test, y_test)\n",
    "    print(\"Lin. Regression Score: \", reg, \"Diff: \", reg-reg_o, \"(\",((reg-reg_o)/reg_o)*100,\"% )\")\n",
    "    print(\"Log. Regression Score: \", log, \"Diff: \", log-log_o, \"(\",((log-log_o)/log_o)*100,\"% )\")  \n",
    "    \n",
    "    #Outliers: One-Class SVM\n",
    "    print(\"--------------Outliers: One-Class SVM--------------\")\n",
    "    y_out = OneClassSVM(nu=0.01).fit_predict(x_train)\n",
    "    mask = y_out != -1\n",
    "    X_train_inl4, y_train_inl4 = x_train[mask, :], y_train[mask]\n",
    "    print(\"Inliers: \",X_train_inl4.shape[0],\"Outliers\",x_train.shape[0]-X_train_inl4.shape[0])\n",
    "    reg, log = make_regression(X_train_inl4, y_train_inl4, x_test, y_test)\n",
    "    print(\"Lin. Regression Score: \", reg, \"Diff: \", reg-reg_o, \"(\",((reg-reg_o)/reg_o)*100,\"% )\")\n",
    "    print(\"Log. Regression Score: \", log, \"Diff: \", log-log_o, \"(\",((log-log_o)/log_o)*100,\"% )\")  \n",
    "\n",
    "   \n",
    "print(\"@@@@@@@@@@@@@@@@@@@@@@---Red Wine---@@@@@@@@@@@@@@@@@@@@@@@\")    \n",
    "print_trainsplit(x_train_red.to_numpy(),x_test_red.to_numpy())\n",
    "make_outliers(x_train_red.to_numpy(), y_train_red.to_numpy(), x_test_red.to_numpy(), y_test_red.to_numpy())\n",
    "print(\"@@@@@@@@@@@@@@@@@@@@@@---White Wine---@@@@@@@@@@@@@@@@@@@@@@@\")\n",
    "print_trainsplit(x_train_white.to_numpy(),x_test_white.to_numpy())\n",
    "make_outliers(x_train_white.to_numpy(), y_train_white.to_numpy(), x_test_white.to_numpy(), y_test_white.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Start:  1607960402.1505842\n",
      "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0               7.4              0.70         0.00             1.9       0.08   \n",
      "1               7.8              0.88         0.00             2.6       0.10   \n",
      "2               7.8              0.76         0.04             2.3       0.09   \n",
      "3              11.2              0.28         0.56             1.9       0.08   \n",
      "4               7.4              0.70         0.00             1.9       0.08   \n",
      "...             ...               ...          ...             ...        ...   \n",
      "1592            6.8              0.62         0.08             1.9       0.07   \n",
      "1594            5.9              0.55         0.10             2.2       0.06   \n",
      "1595            6.3              0.51         0.13             2.3       0.08   \n",
      "1596            5.9              0.65         0.12             2.0       0.08   \n",
      "1597            6.0              0.31         0.47             3.6       0.07   \n",
      "\n",
      "      free sulfur dioxide  total sulfur dioxide    pH  sulphates  magnesium  \\\n",
      "0                    11.0                  34.0  3.51       0.56       0.86   \n",
      "1                    25.0                  67.0  3.20       0.68       0.56   \n",
      "2                    15.0                  54.0  3.26       0.65       0.47   \n",
      "3                    17.0                  60.0  3.16       0.58       0.33   \n",
      "4                    11.0                  34.0  3.51       0.56       0.91   \n",
      "...                   ...                   ...   ...        ...        ...   \n",
      "1592                 28.0                  38.0  3.42       0.82       0.05   \n",
      "1594                 39.0                  51.0  3.52       0.76       0.82   \n",
      "1595                 29.0                  40.0  3.42       0.75       0.71   \n",
      "1596                 32.0                  44.0  3.57       0.71       0.33   \n",
      "1597                 18.0                  42.0  3.39       0.66       0.17   \n",
      "\n",
      "      alcohol  lightness  \n",
      "0         9.4      0.109  \n",
      "1         9.8      0.107  \n",
      "2         9.8      0.106  \n",
      "3         9.8      0.111  \n",
      "4         9.4      0.107  \n",
      "...       ...        ...  \n",
      "1592      9.5      0.110  \n",
      "1594     11.2      0.090  \n",
      "1595     11.0      0.095  \n",
      "1596     10.2      0.104  \n",
      "1597     11.0      0.099  \n",
      "\n",
      "[1564 rows x 12 columns]\n",
      "0       5\n",
      "1       5\n",
      "2       5\n",
      "3       6\n",
      "4       5\n",
      "       ..\n",
      "1592    6\n",
      "1594    6\n",
      "1595    6\n",
      "1596    5\n",
      "1597    6\n",
      "Name: quality, Length: 1564, dtype: int64\n",
      "(1564, 12)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-157-e4c2d673c709>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mx_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#x_y= np.concatenate((x.reshape(1251,14),y.reshape(1251,1)),1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mx_y\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1564\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1564\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;31m#print(x_y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m#print(iris.target_names)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5138\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "#Wrapper approaches\n",
    "#Backward elimination using Recursive feature elimination¶\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import feature_selection\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "######Timer######\n",
    "start_time = time.time()\n",
    "print(\"Execution Start: \", start_time)\n",
    "#################\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "x = x_train_red.to_numpy()\n",
    "y = y_train_red.to_numpy()\n",
    "#x = df_red.iloc[:,0:14].to_numpy()\n",
    "#y = df_red.iloc[:,14].to_numpy()\n",
    "print(x)\n",
    "print(y)\n",
    "print(x.shape)\n",
    "x_y = 0\n",
    "#x_y= np.concatenate((x.reshape(1251,14),y.reshape(1251,1)),1)\n",
    "x_y= np.concatenate((x.reshape(1564,14),y.reshape(1564,1)),1)\n",
    "\n",
    "#Create column list\n",
    "#df_columns=x_train_red.columns.values.tolist()\n",
    "df_columns=df_red.iloc[:,0:14].columns.values.tolist()\n",
    "print(df_columns)\n",
    "df_columns2 = np.append(df_columns, np.array('Label'))\n",
    "print(df_columns2)\n",
    "#Create PANDAS data frame\n",
    "df = pd.DataFrame(x_y,columns=df_columns2)\n",
    "\n",
    "print(\"\\nOriginal Iris Data Set:\")\n",
    "print(df)\n",
    "for i in range(2,14):\n",
    "    #Create the RFE object and rank features\n",
    "    num_features=i\n",
    "    svc = SVC(kernel=\"linear\", C=1)\n",
    "    rfe = feature_selection.RFE(estimator=svc, n_features_to_select=num_features, step=1)\n",
    "    rfe.fit(x, y)\n",
    "\n",
    "    #extend column-mask by one column for the label (always true)\n",
    "    column_mask=np.append(rfe.support_,True)\n",
    "    #use list column_mask to mask df-columns list\n",
    "    reduced_features = [df_columns2[i] for i in range(len(df_columns2)) if column_mask[i]]\n",
    "    print(\"Reduced_features: \",reduced_features)\n",
    "    reduced_df=df[reduced_features]\n",
    "\n",
    "    print(\"\\nIris Data Set reduced to \",num_features,\" features: \\n\",reduced_df)\n",
    "\n",
    "\n",
    "    x_train_red, x_test_red, y_train_red, y_test_red = train_test_split(reduced_df.iloc[:,0:i], reduced_df.iloc[:,i], test_size=0.2, random_state=1)\n",
    "\n",
    "    reg, log = make_regression(x_train_red, y_train_red, x_test_red, y_test_red)\n",
    "    print(\"Lin. Regression Score: \", reg)\n",
    "    print(\"Log. Regression Score: \", log)\n",
    "\n",
    "reduced_df_NA = reduced_df[reduced_df.isna().any(axis=1)]\n",
    "print(reduced_df_NA)\n",
    "\n",
    "######Timer######\n",
    "end_time = time.time()\n",
    "print(\"Execution End: \", end_time)\n",
    "print(\"Execution time: \", end_time-start_time)\n",
    "#################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reduced_df.iloc[:,0:2])\n",
    "print(reduced_df.iloc[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red Wine default Scores:  0.3261973111225165 (Lin.Regr.)  0.5910543130990416 (Log.Regr.)\n",
      "White Wine default Scores:  0.2391827350786282 (Lin.Regr.)  0.4759467758444217 (Log.Regr.)\n",
      "Red scaled normal Scores:  0.32619731112251593 (Lin.Regr.)  0.5623003194888179 (Log.Regr.)\n",
      "White scaled normal Scores:  0.23918273507863086 (Lin.Regr.)  0.49027635619242577 (Log.Regr.)\n",
      "Red filtered Isolation Forest Scores:  0.3655076764744919 (Lin.Regr.)  0.6060606060606061 (Log.Regr.)\n",
      "White filtered Isolation Forest Scores:  0.21035419459657112 (Lin.Regr.)  0.5086206896551724 (Log.Regr.)\n",
      "Red filtered Local Outlier Factor Scores:  0.2709566786782315 (Lin.Regr.)  0.5526315789473685 (Log.Regr.)\n",
      "White filtered Local Outlier Factor Scores:  0.2607734617332562 (Lin.Regr.)  0.5263157894736842 (Log.Regr.)\n",
      "Red One-Class SVM Scores:  0.3193219084628137 (Lin.Regr.)  0.6006711409395973 (Log.Regr.)\n",
      "white One-Class SVM Scores:  0.27916367935930964 (Lin.Regr.)  0.5247844827586207 (Log.Regr.)\n",
      "Red PowerTransformer (default. Datensatz) Scores:  0.33866104708358913 (Lin.Regr.)  0.5910543130990416 (Log.Regr.)\n",
      "Red PowerTransformer (skalierter Datensatz) Scores:  0.33866104708358913 (Lin.Regr.)  0.5718849840255591 (Log.Regr.)\n",
      "red Robust Scaler Scores:  0.32619731112251593 (Lin.Regr.)  0.5910543130990416 (Log.Regr.)\n",
      "white Robust Scaler Scores:  0.23918273507863086 (Lin.Regr.)  0.49437052200614123 (Log.Regr.)\n",
      "Red PowerTransformer (Ohne Outlier) Scores:  0.4430299478126545 (Lin.Regr.)  0.6195286195286195 (Log.Regr.)\n",
      "white PowerTransformer (Ohne Outlier) Scores:  0.21449887663968847 (Lin.Regr.)  0.47737068965517243 (Log.Regr.)\n",
      "Red Minimum Covariance Determinant Scores:  0.4430299478126545 (Lin.Regr.)  0.6127946127946128 (Log.Regr.)\n",
      "White Minimum Covariance Determinant Scores:  0.20544198497840793 (Lin.Regr.)  0.48060344827586204 (Log.Regr.)\n",
      "Red without outlier scaled Scores:  0.4430299478126545 (Lin.Regr.)  0.6195286195286195 (Log.Regr.)\n",
      "White without outlier scaled Scores:  0.2054419849784075 (Lin.Regr.)  0.47737068965517243 (Log.Regr.)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest Reg. Score:  0.4430299478126545 with 10 features\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest Reg. Score:  0.27916367935930964 with 6 features\n"
     ]
    }
   ],
   "source": [
    "#test aller Anpassungen\n",
    "import matplotlib.pyplot as plt\n",
    "my_list_kindR = []\n",
    "my_list_kindW = []\n",
    "my_list_regR = []\n",
    "my_list_regW = []\n",
    "\n",
    "x_train, x_test, y_train, y_test=make_trainsplit(x_red, y_red)\n",
    "reg, log=make_regression(x_train, y_train,x_test, y_test)\n",
    "print(\"Red Wine default Scores: \",reg,\"(Lin.Regr.) \", log, \"(Log.Regr.)\")\n",
    "my_list_kindR.append(\"R def.\")\n",
    "my_list_regR.append(reg)\n",
    "\n",
    "x_train, x_test, y_train, y_test=make_trainsplit(x_white, y_white)\n",
    "reg, log=make_regression(x_train, y_train,x_test, y_test)\n",
    "print(\"White Wine default Scores: \",reg,\"(Lin.Regr.) \", log, \"(Log.Regr.)\")\n",
    "my_list_kindW.append(\"W def.\")\n",
    "my_list_regW.append(reg)\n",
    "\n",
    "x_train, x_test, y_train, y_test=make_trainsplit(x_red_scaled, y_red)\n",
    "reg, log=make_regression(x_train, y_train,x_test, y_test)\n",
    "print(\"Red scaled normal Scores: \",reg,\"(Lin.Regr.) \", log, \"(Log.Regr.)\")\n",
    "my_list_kindR.append(\"R sc. Min/max\")\n",
    "my_list_regR.append(reg)\n",
    "\n",
    "x_train, x_test, y_train, y_test=make_trainsplit(x_white_scaled, y_white)\n",
    "reg, log=make_regression(x_train, y_train,x_test, y_test)\n",
    "print(\"White scaled normal Scores: \",reg,\"(Lin.Regr.) \", log, \"(Log.Regr.)\")\n",
    "my_list_kindW.append(\"W sc. Min/max\")\n",
    "my_list_regW.append(reg)\n",
    "\n",
    "x_train, x_test, y_train, y_test=make_trainsplit(x_red_iso, y_red_iso)\n",
    "reg, log=make_regression(x_train, y_train,x_test, y_test)\n",
    "print(\"Red filtered Isolation Forest Scores: \",reg,\"(Lin.Regr.) \", log, \"(Log.Regr.)\")\n",
    "my_list_kindR.append(\"R Iso. For.\")\n",
    "my_list_regR.append(reg)\n",
    "\n",
    "x_train, x_test, y_train, y_test=make_trainsplit(x_white_iso, y_white_iso)\n",
    "reg, log=make_regression(x_train, y_train,x_test, y_test)\n",
    "print(\"White filtered Isolation Forest Scores: \",reg,\"(Lin.Regr.) \", log, \"(Log.Regr.)\")\n",
    "my_list_kindW.append(\"W Iso. For.\")\n",
    "my_list_regW.append(reg)\n",
    "\n",
    "x_train, x_test, y_train, y_test=make_trainsplit(x_red_lof, y_red_lof)\n",
    "reg, log=make_regression(x_train, y_train,x_test, y_test)\n",
    "print(\"Red filtered Local Outlier Factor Scores: \",reg,\"(Lin.Regr.) \", log, \"(Log.Regr.)\")\n",
    "my_list_kindR.append(\"R LOF\")\n",
    "my_list_regR.append(reg)\n",
    "\n",
    "x_train, x_test, y_train, y_test=make_trainsplit(x_white_lof, y_white_lof)\n",
    "reg, log=make_regression(x_train, y_train,x_test, y_test)\n",
    "print(\"White filtered Local Outlier Factor Scores: \",reg,\"(Lin.Regr.) \", log, \"(Log.Regr.)\")\n",
    "my_list_kindW.append(\"W LOF\")\n",
    "my_list_regW.append(reg)\n",
    "\n",
    "x_train, x_test, y_train, y_test=make_trainsplit(x_red_ocs, y_red_ocs)\n",
    "reg, log=make_regression(x_train, y_train,x_test, y_test)\n",
    "print(\"Red One-Class SVM Scores: \",reg,\"(Lin.Regr.) \", log, \"(Log.Regr.)\")\n",
    "my_list_kindR.append(\"R O.-C. SVM\")\n",
    "my_list_regR.append(reg)\n",
    "\n",
    "x_train, x_test, y_train, y_test=make_trainsplit(x_white_ocs, y_white_ocs)\n",
    "reg, log=make_regression(x_train, y_train,x_test, y_test)\n",
    "print(\"white One-Class SVM Scores: \",reg,\"(Lin.Regr.) \", log, \"(Log.Regr.)\")\n",
    "my_list_kindW.append(\"R O.-C. SVM\")\n",
    "my_list_regW.append(reg)\n",
    "\n",
    "x_train, x_test, y_train, y_test=make_trainsplit(x_red_pt, y_red)\n",
    "reg, log=make_regression(x_train, y_train,x_test, y_test)\n",
    "print(\"Red PowerTransformer (default. Datensatz) Scores: \",reg,\"(Lin.Regr.) \", log, \"(Log.Regr.)\")\n",
    "my_list_kindR.append(\"R P.Trans. def.\")\n",
    "my_list_regR.append(reg)\n",
    "\n",
    "x_train, x_test, y_train, y_test=make_trainsplit(x_red_pt_scaled, y_red)\n",
    "reg, log=make_regression(x_train, y_train,x_test, y_test)\n",
    "print(\"Red PowerTransformer (skalierter Datensatz) Scores: \",reg,\"(Lin.Regr.) \", log, \"(Log.Regr.)\")\n",
    "my_list_kindR.append(\"R P.Trans. sc.\")\n",
    "my_list_regR.append(reg)\n",
    "\n",
    "x_train, x_test, y_train, y_test=make_trainsplit(x_red_robust, y_red)\n",
    "reg, log=make_regression(x_train, y_train,x_test, y_test)\n",
    "print(\"red Robust Scaler Scores: \",reg,\"(Lin.Regr.) \", log, \"(Log.Regr.)\")\n",
    "my_list_kindR.append(\"R R. Scaler\")\n",
    "my_list_regR.append(reg)\n",
    "\n",
    "x_train, x_test, y_train, y_test=make_trainsplit(x_white_robust, y_white)\n",
    "reg, log=make_regression(x_train, y_train,x_test, y_test)\n",
    "print(\"white Robust Scaler Scores: \",reg,\"(Lin.Regr.) \", log, \"(Log.Regr.)\")\n",
    "my_list_kindW.append(\"W R. Scaler\")\n",
    "my_list_regW.append(reg)\n",
    "\n",
    "x_train, x_test, y_train, y_test=make_trainsplit(x_red_mcd_scaled, y_red_mcd)\n",
    "reg, log=make_regression(x_train, y_train,x_test, y_test)\n",
    "print(\"Red PowerTransformer (Ohne Outlier) Scores: \",reg,\"(Lin.Regr.) \", log, \"(Log.Regr.)\")\n",
    "my_list_kindR.append(\"R P.Trans. sc. w/o outl.\")\n",
    "my_list_regR.append(reg)\n",
    "\n",
    "x_train, x_test, y_train, y_test=make_trainsplit(x_white_mcd_scaled_pt, y_white_mcd)\n",
    "reg, log=make_regression(x_train, y_train,x_test, y_test)\n",
    "print(\"white PowerTransformer (Ohne Outlier) Scores: \",reg,\"(Lin.Regr.) \", log, \"(Log.Regr.)\")\n",
    "my_list_kindW.append(\"W P.Trans. sc. w/o out.\")\n",
    "my_list_regW.append(reg)\n",
    "\n",
    "x_train, x_test, y_train, y_test=make_trainsplit(x_red_mcd, y_red_mcd)\n",
    "reg, log=make_regression(x_train, y_train,x_test, y_test)\n",
    "print(\"Red Minimum Covariance Determinant Scores: \",reg,\"(Lin.Regr.) \", log, \"(Log.Regr.)\")\n",
    "my_list_kindR.append(\"R MCD\")\n",
    "my_list_regR.append(reg)\n",
    "\n",
    "x_train, x_test, y_train, y_test=make_trainsplit(x_white_mcd, y_white_mcd)\n",
    "reg, log=make_regression(x_train, y_train,x_test, y_test)\n",
    "print(\"White Minimum Covariance Determinant Scores: \",reg,\"(Lin.Regr.) \", log, \"(Log.Regr.)\")\n",
    "my_list_kindW.append(\"W MCD\")\n",
    "my_list_regW.append(reg)\n",
    "\n",
    "x_train, x_test, y_train, y_test=make_trainsplit(x_red_mcd_scaled, y_red_mcd)\n",
    "reg, log=make_regression(x_train, y_train,x_test, y_test)\n",
    "print(\"Red without outlier scaled Scores: \",reg,\"(Lin.Regr.) \", log, \"(Log.Regr.)\")\n",
    "my_list_kindR.append(\"R sc. MCD w/o outliner\")\n",
    "my_list_regR.append(reg)\n",
    "\n",
    "x_train, x_test, y_train, y_test=make_trainsplit(x_white_mcd_scaled, y_white_mcd)\n",
    "reg, log=make_regression(x_train, y_train,x_test, y_test)\n",
    "print(\"White without outlier scaled Scores: \",reg,\"(Lin.Regr.) \", log, \"(Log.Regr.)\")\n",
    "my_list_kindW.append(\"W sc. MCD w/o outliner\")\n",
    "my_list_regW.append(reg)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,8))\n",
    "ax.scatter(my_list_kindR, my_list_regR)   \n",
    "ax.set_ylabel('linear regression score')\n",
    "ax.set_xlabel('used dataset')\n",
    "#plt.plot(my_list_kindR, my_list_regR)\n",
    "plt.show()  \n",
    "\n",
    "import operator\n",
    "index, value = max(enumerate(my_list_regR), key=operator.itemgetter(1))\n",
    "print(\"Highest Reg. Score: \",value, \"with\",index+2,\"features\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,8))\n",
    "ax.scatter(my_list_kindW, my_list_regW)   \n",
    "ax.set_ylabel('linear regression score')\n",
    "ax.set_xlabel('used dataset')\n",
    "#plt.plot(my_list_kindW, my_list_regW)\n",
    "plt.show()  \n",
    "\n",
    "index, value = max(enumerate(my_list_regW), key=operator.itemgetter(1))\n",
    "print(\"Highest Reg. Score: \",value, \"with\",index+2,\"features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Accuracy:\n",
      "Linear regression:  0.5158249158249157\n",
      "Logistic regression (one vs. rest):  0.3245791245791246\n",
      "Logistic regression (multinomial):  0.14612794612794616\n",
      "Ordered logistic regression:  nan\n",
      "3\n",
      "Accuracy:\n",
      "Linear regression:  0.569023569023569\n",
      "Logistic regression (one vs. rest):  0.36767676767676766\n",
      "Logistic regression (multinomial):  0.26329966329966326\n",
      "Ordered logistic regression:  nan\n",
      "4\n",
      "Accuracy:\n",
      "Linear regression:  0.5663299663299662\n",
      "Logistic regression (one vs. rest):  0.36363636363636365\n",
      "Logistic regression (multinomial):  0.3070707070707071\n",
      "Ordered logistic regression:  nan\n",
      "5\n",
      "Accuracy:\n",
      "Linear regression:  0.5777777777777777\n",
      "Logistic regression (one vs. rest):  0.3865319865319865\n",
      "Logistic regression (multinomial):  0.33131313131313134\n",
      "Ordered logistic regression:  nan\n",
      "6\n",
      "Accuracy:\n",
      "Linear regression:  0.597979797979798\n",
      "Logistic regression (one vs. rest):  0.4094276094276094\n",
      "Logistic regression (multinomial):  0.3488215488215488\n",
      "Ordered logistic regression:  nan\n",
      "7\n",
      "Accuracy:\n",
      "Linear regression:  0.5973063973063973\n",
      "Logistic regression (one vs. rest):  0.40606060606060607\n",
      "Logistic regression (multinomial):  0.34680134680134683\n",
      "Ordered logistic regression:  nan\n",
      "8\n",
      "Accuracy:\n",
      "Linear regression:  0.5973063973063972\n",
      "Logistic regression (one vs. rest):  0.4067340067340067\n",
      "Logistic regression (multinomial):  0.34276094276094277\n",
      "Ordered logistic regression:  nan\n",
      "9\n",
      "Accuracy:\n",
      "Linear regression:  0.597979797979798\n",
      "Logistic regression (one vs. rest):  0.4175084175084175\n",
      "Logistic regression (multinomial):  0.35353535353535354\n",
      "Ordered logistic regression:  nan\n",
      "10\n",
      "Accuracy:\n",
      "Linear regression:  0.6006734006734007\n",
      "Logistic regression (one vs. rest):  0.41952861952861953\n",
      "Logistic regression (multinomial):  0.35690235690235694\n",
      "Ordered logistic regression:  nan\n",
      "11\n",
      "Accuracy:\n",
      "Linear regression:  0.6047138047138046\n",
      "Logistic regression (one vs. rest):  0.41952861952861953\n",
      "Logistic regression (multinomial):  0.3589225589225589\n",
      "Ordered logistic regression:  nan\n",
      "12\n",
      "Accuracy:\n",
      "Linear regression:  0.6\n",
      "Logistic regression (one vs. rest):  0.42558922558922563\n",
      "Logistic regression (multinomial):  0.3582491582491582\n",
      "Ordered logistic regression:  nan\n",
      "Highest Lin. Reg. Score:  0.6047138047138046\n",
      "Highest Log. Reg. (one vs. rest) Score:  0.42558922558922563\n",
      "Highest Log. Reg. (multinomial) Score:  0.3589225589225589\n",
      "Highest Ordered Log. Reg. Score:  nan\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import decomposition\n",
    "from sklearn import datasets\n",
    "import seaborn as sns\n",
    "#Create Seaborn scatter matrix\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "\n",
    "##Erste Darstellung \n",
    "#df_red_org_new=df_red_org.drop(\"flavanoids\", axis=1)\n",
    "#g = sns.pairplot(df_red_org_new,hue=\"quality\")\n",
    "\n",
    "my_list_lin = []\n",
    "my_list_1vR = []\n",
    "my_list_multi= []\n",
    "my_list_ord=[]\n",
    "\n",
    "for i in range(2,13):\n",
    "    #Perform PCA with 2 dimensions\n",
    "    num_components=i\n",
    "    pca = decomposition.PCA(n_components=num_components)\n",
    "    #Only use features\n",
    "    #x=x_red_mcd_scaled\n",
    "    #y=y_red_mcd\n",
    "    x=x_red_iso\n",
    "    y=y_red_iso\n",
    "    pca.fit(x)\n",
    "    x_tran = pca.transform(x)\n",
    "    print(i)\n",
    "    #Reconstruct data frame\n",
    "    \n",
    "    x_y=0\n",
    "    x_y= np.concatenate((x_tran.reshape(1485,num_components),y.values.reshape(1485,1)),1)\n",
    "    tran = pd.DataFrame(x_y)\n",
    "    acc_linear, acc_1vR, acc_multi,acc_ordinal = make_all_regression(tran.iloc[:,0:i],tran.iloc[:,i])\n",
    "\n",
    "#Plot iris data in seaborn scatter matrix\n",
    "#sns.set(style=\"ticks\")\n",
    "#sns.pairplot(tran, hue=\"quality\")\n",
    "ax.plot(my_list_i, my_list_lin)\n",
    "ax.plot(my_list_i, my_list_1vR)\n",
    "ax.plot(my_list_i, my_list_multi)\n",
    "ax.plot(my_list_i, my_list_ord)\n",
    "ax.set_ylabel('regression score')\n",
    "ax.set_xlabel('number of features')\n",
    "ax.legend(my_list_type[0:3])\n",
    "#plt.plot(my_list_i, my_list_reg)\n",
    "plt.show()   \n",
    "\n",
    "import operator\n",
    "index, value = max(enumerate(my_list_lin), key=operator.itemgetter(1))\n",
    "print(\"Highest Lin. Reg. Score: \",value)\n",
    "\n",
    "index, value = max(enumerate(my_list_1vR), key=operator.itemgetter(1))\n",
    "print(\"Highest Log. Reg. (one vs. rest) Score: \",value)\n",
    "\n",
    "index, value = max(enumerate(my_list_multi), key=operator.itemgetter(1))\n",
    "print(\"Highest Log. Reg. (multinomial) Score: \",value)\n",
    "\n",
    "index, value = max(enumerate(my_list_ord), key=operator.itemgetter(1))\n",
    "print(\"Highest Ordered Log. Reg. Score: \",value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0341668  0.10793181 0.06130488 0.0391394  0.03457086 0.01598485\n",
      " 0.07861729 0.02353518 0.09934111 0.03542167 0.16142354 0.09439585]\n",
      "(1564, 12)\n",
      "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0          0.247788          0.397260         0.00        0.068493   0.116667   \n",
      "1          0.283186          0.520548         0.00        0.116438   0.150000   \n",
      "2          0.283186          0.438356         0.04        0.095890   0.133333   \n",
      "3          0.584071          0.109589         0.56        0.068493   0.116667   \n",
      "4          0.247788          0.397260         0.00        0.068493   0.116667   \n",
      "...             ...               ...          ...             ...        ...   \n",
      "1480       0.194690          0.342466         0.08        0.068493   0.100000   \n",
      "1481       0.115044          0.294521         0.10        0.089041   0.083333   \n",
      "1482       0.150442          0.267123         0.13        0.095890   0.116667   \n",
      "1483       0.115044          0.363014         0.12        0.075342   0.116667   \n",
      "1484       0.123894          0.130137         0.47        0.184932   0.100000   \n",
      "\n",
      "      free sulfur dioxide  total sulfur dioxide        pH  sulphates  \\\n",
      "0                0.140845              0.098940  0.089953   0.137725   \n",
      "1                0.338028              0.215548  0.053738   0.209581   \n",
      "2                0.197183              0.169611  0.060748   0.191617   \n",
      "3                0.225352              0.190813  0.049065   0.149701   \n",
      "4                0.140845              0.098940  0.089953   0.137725   \n",
      "...                   ...                   ...       ...        ...   \n",
      "1480             0.380282              0.113074  0.079439   0.293413   \n",
      "1481             0.535211              0.159011  0.091121   0.257485   \n",
      "1482             0.394366              0.120141  0.079439   0.251497   \n",
      "1483             0.436620              0.134276  0.096963   0.227545   \n",
      "1484             0.239437              0.127208  0.075935   0.197605   \n",
      "\n",
      "      magnesium   alcohol  lightness  \n",
      "0          0.86  0.153846   0.666667  \n",
      "1          0.56  0.215385   0.631579  \n",
      "2          0.47  0.215385   0.614035  \n",
      "3          0.33  0.215385   0.701754  \n",
      "4          0.91  0.153846   0.631579  \n",
      "...         ...       ...        ...  \n",
      "1480       0.05  0.169231   0.684211  \n",
      "1481       0.82  0.430769   0.333333  \n",
      "1482       0.71  0.400000   0.421053  \n",
      "1483       0.33  0.276923   0.578947  \n",
      "1484       0.17  0.400000   0.491228  \n",
      "\n",
      "[1485 rows x 12 columns]\n",
      "Nr. of features:  2\n",
      "['alcohol', 'lightness', 'quality']\n",
      "Accuracy:\n",
      "Linear regression:  0.553094535922012\n",
      "Logistic regression (one vs. rest):  0.4827680838862947\n",
      "Logistic regression (multinomial):  0.2884369623986237\n",
      "Ordered logistic regression:  nan\n",
      "Nr. of features:  3\n",
      "['sulphates', 'alcohol', 'lightness', 'quality']\n",
      "Accuracy:\n",
      "Linear regression:  0.5633407061522078\n",
      "Logistic regression (one vs. rest):  0.4520357172114361\n",
      "Logistic regression (multinomial):  0.25957442451052676\n",
      "Ordered logistic regression:  nan\n",
      "Nr. of features:  4\n",
      "['volatile acidity', 'sulphates', 'alcohol', 'lightness', 'quality']\n",
      "Accuracy:\n",
      "Linear regression:  0.5767633325141313\n",
      "Logistic regression (one vs. rest):  0.43992176619972145\n",
      "Logistic regression (multinomial):  0.37277586630621773\n",
      "Ordered logistic regression:  nan\n",
      "Nr. of features:  5\n",
      "['volatile acidity', 'total sulfur dioxide', 'sulphates', 'alcohol', 'lightness', 'quality']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-162-9785ac66e251>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mmy_list_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m#my_list_reg.append(reg)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0macc_linear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_1vR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_multi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc_ordinal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_all_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduced_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreduced_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;31m#my_list_lin.append(np.mean(acc_linear))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m#my_list_1vR.append(np.mean(acc_1vR))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-73-2b1cd8edb89e>\u001b[0m in \u001b[0;36mmake_all_regression\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     66\u001b[0m         scoring=MAE)\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m#print('Logistic regression (one versus rest): ', np.mean(MAE_1vR))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     MAE_multi = cross_val_score(model_multi,\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n\u001b[0m\u001b[1;32m    402\u001b[0m                                 \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    240\u001b[0m     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n\u001b[1;32m    241\u001b[0m                         pre_dispatch=pre_dispatch)\n\u001b[0;32m--> 242\u001b[0;31m     scores = parallel(\n\u001b[0m\u001b[1;32m    243\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    244\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    864\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m             \u001b[0mprefer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'processes'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[1;32m   1408\u001b[0m                                \u001b[0;34m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprefer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m             path_func(X, y, pos_class=class_, Cs=[C_],\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    864\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    755\u001b[0m             iprint = [-1, 50, 1, 100, 101][\n\u001b[1;32m    756\u001b[0m                 np.searchsorted(np.array([0, 1, 2, 3]), verbose)]\n\u001b[0;32m--> 757\u001b[0;31m             opt_res = optimize.minimize(\n\u001b[0m\u001b[1;32m    758\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"L-BFGS-B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    615\u001b[0m                                   **options)\n\u001b[1;32m    616\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 617\u001b[0;31m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[1;32m    618\u001b[0m                                 callback=callback, **options)\n\u001b[1;32m    619\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfev\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;34m\"\"\" returns the the function value \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfunc\u001b[0;34m(x, *args)\u001b[0m\n\u001b[1;32m    733\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_multi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m             \u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0m_multinomial_loss_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'newton-cg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0m_multinomial_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_multinomial_loss_grad\u001b[0;34m(w, X, Y, alpha, sample_weight)\u001b[0m\n\u001b[1;32m    345\u001b[0m     grad = np.zeros((n_classes, n_features + bool(fit_intercept)),\n\u001b[1;32m    346\u001b[0m                     dtype=X.dtype)\n\u001b[0;32m--> 347\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_multinomial_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m     \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_multinomial_loss\u001b[0;34m(w, X, Y, alpha, sample_weight)\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mintercept\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlogsumexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msquared_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/scipy/special/_logsumexp.py\u001b[0m in \u001b[0;36mlogsumexp\u001b[0;34m(a, axis, b, keepdims, return_sign)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0msgn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0msgn\u001b[0m  \u001b[0;31m# /= makes more sense but we need zero -> zero\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Information gain classifier\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.metrics import adjusted_mutual_info_score\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mi = mutual_info_regression(x_red, y_red)\n",
    "print(mi)\n",
    "\n",
    "#Automatically adjust columns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "x=x_red\n",
    "y=y_red\n",
    "#x=x_white_ocs\n",
    "#y=y_white_ocs\n",
    "#Construct data frame\n",
    "print(x_red.shape)\n",
    "column_names_old=x.columns.values.tolist()\n",
    "column_names = np.append(column_names_old, np.array('quality'))\n",
    "#column_names=['a'+str(i) for i in range(1, x.shape[1]+1)]\n",
    "#column_names.append('quality')\n",
    "df=pd.DataFrame(np.column_stack([x,y]),columns=column_names)\n",
    "##print('Original data frame:',df.head)\n",
    "my_list_i = []\n",
    "my_list_reg = []\n",
    "\n",
    "my_list_lin = []\n",
    "my_list_1vR = []\n",
    "my_list_multi= []\n",
    "#my_list_ord=[]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,8))\n",
    "print(x_red_iso)\n",
    "for i in range(2,13):\n",
    "    #Select 10 features using Mutual Information = Information Gain\n",
    "    print(\"Nr. of features: \",i)\n",
    "    sel = SelectKBest(mutual_info_classif, k=i)\n",
    "    sel.fit(x, y)\n",
    "    remaining_columns= df.columns[sel.get_support(indices=True)] \n",
    "    remaining_columns= remaining_columns.insert(len(remaining_columns),'quality')\n",
    "    reduced_df=df[remaining_columns]\n",
    "    print(reduced_df.columns.values.tolist())\n",
    "    ##print('Reduced data frame (first rows): \\n',reduced_df)\n",
    "    #x_train, x_test, y_train, y_test=make_trainsplit(reduced_df.iloc[:,0:i], reduced_df.iloc[:,i])\n",
    "    #reg, log=make_regression(x_train, y_train,x_test, y_test)\n",
    "    #print(\"Mutal Information classifier with features=\",i,\": \",reg,\"(Lin.Regr.) \", log, \"(Log.Regr.)\")\n",
    "    my_list_i.append(i)\n",
    "    #my_list_reg.append(reg)\n",
    "    acc_linear, acc_1vR, acc_multi,acc_ordinal = make_all_regression(reduced_df.iloc[:,0:i],reduced_df.iloc[:,i])\n",
    "    #my_list_lin.append(np.mean(acc_linear))\n",
    "    #my_list_1vR.append(np.mean(acc_1vR))\n",
    "    #my_list_multi.append(np.mean(acc_multi))\n",
    "    #my_list_ord.append(np.mean(acc_ordinal))\n",
    "    \n",
    "print(my_list_lin)\n",
    "ax.plot(my_list_i, my_list_lin)\n",
    "#ax.plot(my_list_i, my_list_1vR)\n",
    "#ax.plot(my_list_i, my_list_multi)\n",
    "#ax.plot(my_list_i, my_list_ord)\n",
    "\n",
    "ax.set_ylabel('regression score')\n",
    "ax.set_xlabel('number of features')\n",
    "ax.legend(my_list_type[0:3])\n",
    "#plt.plot(my_list_i, my_list_reg)\n",
    "plt.show()   \n",
    "\n",
    "import operator\n",
    "index, value = max(enumerate(my_list_lin), key=operator.itemgetter(1))\n",
    "print(\"Highest Lin. Reg. Score: \",value)\n",
    "\n",
    "index, value = max(enumerate(my_list_1vR), key=operator.itemgetter(1))\n",
    "print(\"Highest Log. Reg. (one vs. rest) Score: \",value)\n",
    "\n",
    "index, value = max(enumerate(my_list_multi), key=operator.itemgetter(1))\n",
    "print(\"Highest Log. Reg. (multinomial) Score: \",value)\n",
    "\n",
    "index, value = max(enumerate(my_list_ord), key=operator.itemgetter(1))\n",
    "print(\"Highest Ordered Log. Reg. Score: \",value)\n",
    "\n",
    "#fig, ax = plt.subplots(figsize=(16,8))\n",
    "#ax.scatter(my_list_i, my_list_reg)   \n",
    "#ax.set_ylabel('linear regression score')\n",
    "#ax.set_xlabel('number of features')\n",
    "#plt.plot(my_list_i, my_list_reg)\n",
    "#plt.show()   \n",
    "\n",
    "#x_train, x_test, y_train, y_test=make_trainsplit(x[['volatile acidity', 'total sulfur dioxide', 'sulphates', 'alcohol', 'lightness']], y)\n",
    "#reg, log=make_regression(x_train, y_train,x_test, y_test)\n",
    "print(\"Mutal Information classifier with features=\",5,\": \",reg,\"(Lin.Regr.) \", log, \"(Log.Regr.)\")\n",
    "\n",
    "#Mit normiertem total sulfur dioxide\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixed acidity           0\n",
      "volatile acidity        0\n",
      "citric acid             0\n",
      "residual sugar          0\n",
      "chlorides               0\n",
      "free sulfur dioxide     0\n",
      "total sulfur dioxide    0\n",
      "pH                      0\n",
      "sulphates               0\n",
      "magnesium               0\n",
      "alcohol                 0\n",
      "lightness               0\n",
      "dtype: int64\n",
      "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
      "count    1564.000000       1564.000000  1564.000000     1564.000000   \n",
      "mean        8.323210          0.528261     0.270729        2.537052   \n",
      "std         1.748636          0.179835     0.195365        1.411277   \n",
      "min         4.600000          0.120000     0.000000        0.900000   \n",
      "25%         7.100000          0.390000     0.090000        1.900000   \n",
      "50%         7.900000          0.520000     0.260000        2.200000   \n",
      "75%         9.300000          0.640000     0.420000        2.600000   \n",
      "max        15.900000          1.580000     1.000000       15.500000   \n",
      "\n",
      "         chlorides  free sulfur dioxide  total sulfur dioxide           pH  \\\n",
      "count  1564.000000          1564.000000           1564.000000  1564.000000   \n",
      "mean      0.087538             0.209638              0.143098     3.329783   \n",
      "std       0.046052             0.147852              0.116583     0.381398   \n",
      "min       0.010000             0.000000              0.000000     2.740000   \n",
      "25%       0.070000             0.084507              0.056537     3.210000   \n",
      "50%       0.080000             0.183099              0.113074     3.310000   \n",
      "75%       0.090000             0.281690              0.197880     3.400000   \n",
      "max       0.610000             1.000000              1.000000    11.300000   \n",
      "\n",
      "         sulphates    magnesium      alcohol    lightness  \n",
      "count  1564.000000  1564.000000  1564.000000  1564.000000  \n",
      "mean      0.657193     0.498587    10.423146     0.101992  \n",
      "std       0.169399     0.286672     1.064924     0.009588  \n",
      "min       0.330000     0.000000     8.400000     0.071000  \n",
      "25%       0.550000     0.260000     9.500000     0.095000  \n",
      "50%       0.620000     0.510000    10.200000     0.103000  \n",
      "75%       0.730000     0.740000    11.100000     0.110000  \n",
      "max       2.000000     1.000000    14.900000     0.128000  \n",
      "Lin. Regression Score:  0.32619731112251615 (Lin.Regr.)  0.5782747603833865 (Log.Regr.)\n",
      "Accuracy:\n",
      "Linear regression:  0.5888998115835176\n",
      "Logistic regression (one vs. rest):  0.4405627918407471\n",
      "Logistic regression (multinomial):  0.37663021217334314\n",
      "Ordered logistic regression:  0.5940157286802654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.58146965, 0.56230032, 0.59105431, 0.58146965, 0.62820513]),\n",
       " array([0.47284345, 0.41214058, 0.45047923, 0.38658147, 0.48076923]),\n",
       " array([0.42811502, 0.34824281, 0.35782748, 0.32268371, 0.42628205]),\n",
       " array([0.58146965, 0.57188498, 0.60702875, 0.57507987, 0.63461538]))"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mms = MinMaxScaler()\n",
    "x_red_new1 = x_red.copy()\n",
    "x_red_new1[['total sulfur dioxide','free sulfur dioxide']] = mms.fit_transform(x_red_new1[['total sulfur dioxide','free sulfur dioxide']])\n",
    "print(x_red_new1.isnull().sum())\n",
    "print(x_red_new1.describe())\n",
    "\n",
    "x_train, x_test, y_train, y_test=make_trainsplit(x_red_new1, y_red)\n",
    "reg, log=make_regression(x_train, y_train,x_test, y_test)\n",
    "print(\"Lin. Regression Score: \",reg,\"(Lin.Regr.) \", log, \"(Log.Regr.)\")\n",
    "\n",
    "make_all_regression(x_red_new1, y_red)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default\n",
      "Accuracy:\n",
      "Linear regression:  0.5888998115835176\n",
      "Logistic regression (one vs. rest):  0.40665806504464647\n",
      "Logistic regression (multinomial):  0.37276972229048905\n",
      "Ordered logistic regression:  0.5908085524698944\n",
      "scaled\n",
      "Accuracy:\n",
      "Linear regression:  0.5888998115835176\n",
      "Logistic regression (one vs. rest):  0.429055050380929\n",
      "Logistic regression (multinomial):  0.3644773490620136\n",
      "Ordered logistic regression:  0.5940157286802654\n",
      "scaled w/o outlier\n",
      "Accuracy:\n",
      "Linear regression:  0.5939393939393939\n",
      "Logistic regression (one vs. rest):  0.43905723905723903\n",
      "Logistic regression (multinomial):  0.36969696969696975\n",
      "Ordered logistic regression:  0.5878787878787879\n",
      "Iso. forests\n",
      "Accuracy:\n",
      "Linear regression:  0.6\n",
      "Logistic regression (one vs. rest):  0.42558922558922563\n",
      "Logistic regression (multinomial):  0.3575757575757576\n",
      "Ordered logistic regression:  0.6026936026936026\n",
      "local outlier foctor\n",
      "Accuracy:\n",
      "Linear regression:  0.5984453708528747\n",
      "Logistic regression (one vs. rest):  0.42925134618725025\n",
      "Logistic regression (multinomial):  0.3548593017196457\n",
      "Ordered logistic regression:  0.589879711655376\n",
      "mcd\n",
      "Accuracy:\n",
      "Linear regression:  0.5939393939393939\n",
      "Logistic regression (one vs. rest):  0.43299663299663305\n",
      "Logistic regression (multinomial):  0.3595959595959596\n",
      "Ordered logistic regression:  0.5878787878787879\n",
      "O.-C. SVM\n",
      "Accuracy:\n",
      "Linear regression:  0.6009445687298036\n",
      "Logistic regression (one vs. rest):  0.4346778749463313\n",
      "Logistic regression (multinomial):  0.3660271620003164\n",
      "Ordered logistic regression:  0.6009445687298036\n",
      "P.Trans. def.\n",
      "Accuracy:\n",
      "Linear regression:  0.5901736708445974\n",
      "Logistic regression (one vs. rest):  0.4316068649135742\n",
      "Logistic regression (multinomial):  0.3849225854018187\n",
      "Ordered logistic regression:  0.5895346932088146\n",
      "P.Trans scaled\n",
      "Accuracy:\n",
      "Linear regression:  0.5901736708445974\n",
      "Logistic regression (one vs. rest):  0.442467436716638\n",
      "Logistic regression (multinomial):  0.3893872368313263\n",
      "Ordered logistic regression:  0.5895346932088146\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA74AAAHlCAYAAADSqCAcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAABwXklEQVR4nO3deXhN5/7+8XtnNEQMkRBDauiJ4ZiHGGsIJYjG1KKmUpS2dKCE9hAUNZQSx9G0DqWmmivoaUtRJVHVojXWHCKGUJKQxM76/ZGf/W0kJCHJTrb367pyXdlrr+Gz1kpWcu/nWc8yGYZhCAAAAAAAG2Vn7QIAAAAAAMhOBF8AAAAAgE0j+AIAAAAAbBrBFwAAAABg0xysXUBOuHv3rn7//Xe5u7vL3t7e2uUAAAAAALKQ2WzW1atXVa1aNeXLly/V+09F8P3999/Vq1cva5cBAAAAAMhGy5YtU7169VJNfyqCr7u7u6Tkg1CyZEkrVwMAAAAAyEqXL19Wr169LNnvQU9F8L3fvblkyZIqU6aMlasBAAAAAGSHh93ayuBWAAAAAACbRvAFAAAAANg0gi8AAAAAwKYRfAEAAAAANo3gCwAAAACwaQRfAAAAAIBNI/gCAAAAAGwawRcAAAAAYNMIvgAAAAAAm0bwBQAAAADYNIIvAAAAAMCmEXwBAAAAADaN4AsAAAAAsGkEXwAAAACATXOwdgEAgLwr7OJ1rT9+SdF3E1Usn6M6VyqlhqXdrF0WAABACgRfAMBjCbt4XUsPn1dCkiFJir6bqKWHz0sS4RcAAOQqdHUGADyW9ccvWULvfQlJhtYfv2SligAAANJGiy8A4LFE303M1HQAyE2+/X6Ptt5IVEwBF7nExahdUUe1ad3Y2mUByCY51uJ75swZde/eXW3btlX37t119uzZNOfbsmWLOnbsKH9/f3Xs2FHXrl2TJJnNZk2YMEGtW7fW888/r9WrV+dU6QCANBTL55ip6QCQW3z7/R6ti7NXTMFCksmkmIKFtC7OXt9+v8fapQHIJjnW4jt+/Hi9/PLLCggI0MaNGzVu3DgtWbIkxTyHDx/WvHnz9MUXX8jd3V23b9+Wk5OTJGnTpk06f/68vv32W928eVOdOnVSo0aNVKZMmZzaBQDA37RKuq119+xldvi/oGt/L1Gtku5asSoASN/WG4kyF8yXYprZwVFbb9xVGyvVBCB75UiL7/Xr13XkyBH5+/tLkvz9/XXkyBFFR0enmG/x4sUaMGCA3N3dJUmFChWSs7OzpOSW4BdffFF2dnYqVqyYWrdurW+++SbVtm7duqWIiIgUX5cvX87mPQSAp0+xlV+o8Y5QFbx9UzIMFbx9U413hKrYyi+sXRoAPFJMAZdMTQeQ9+VIi29kZKRKlCghe3t7SZK9vb08PDwUGRmpYsWKWeY7deqUypQpo169eikuLk7PP/+8hg4dKpPJpMjISJUqVcoyr6enZ5qB9osvvtC8efOyf6cA4CkXf+26Kl69poqnjqScbjJZqSJI0pWdu3R+6TLFX7su5+Ju8urTSx7Nm1m7LCBXcYmLSe7mnMZ0ALYpVw1uZTabdfz4cS1atEgJCQkaOHCgSpUqpU6dOmV4Hf369VPnzp1TTLt8+bJ69eqVxdUCwNPNubib4q9eS3M6rOPKzl069e8FSoqPlyTFX72mU/9eIEmEX+Bv2hV11Lq4xFS3arQryhgFgK3Kka7Onp6eioqKktlslpQccK9cuSJPT88U85UqVUp+fn5ycnKSi4uLWrVqpUOHDlnWcenS/z0iIzIyUiVLlky1LVdXV5UpUybFV1rzAQCejFefXrL7/7ej3Gfn7CyvPnzQaC3nly6zhN77kuLjdX7pMitVBORObVo3VpcCZrnE3pYMQy6xt9WlgJlRnQEbliMtvm5ubqpSpYpCQ0MVEBCg0NBQValSJUU3Zyn53t+dO3cqICBA9+7dU1hYmNq2bStJ8vPz0+rVq9WmTRvdvHlT33//vZYt4w85AFjL/RZEutXmHvHXrmdqOvA0a9O6MQNZAU+RHOvqHBQUpMDAQM2fP1+urq6aNm2aJGnQoEEaPny4qlevrg4dOuj3339X+/btZWdnp6ZNm6pbt26SpICAAB08eFBt2iRfot544w2VLVs2p8oHAKTBo3kzgm4uQvdzAADSZjIMw7B2EdktIiJCrVq10rZt23j8EQDAZj14j6+U3P284htD+IACAGDT0st8uWpwKwAA8Pjofg4AQNoIvkAawi5e1/rjlxR9N1HF8jmqc6VSaliaroLWxmNagPTR/Tx34voFANZF8AUeEHbxupYePq+EpOS7AKLvJmrp4fOSRPi1Ih7TAiCv4voFANaXI48zAvKS9ccvWULvfQlJhtYfv/SQJZATeEwLgLyK6xcAWB/BF3hA9N3ETE1HzuAxLQDyKq5fAGB9BF/gAcXyOWZqOnLGwx7HwmNaAOR2XL8AwPoIvrlA2MXrGr39sAZtOaDR2w8r7CKfAFtT50ql5GRnSjHNyc6kzpVKWakiSJJXn16yc3ZOMc3O2VlefXpZqSIAyBiuXwBgfQxuZWUMpJT73D/ujOqcu/CYFgB5FdcvIOMYAT33sZVzQvC1skcNpETQsp6Gpd04/rkQj2kB0sfj2HInrl9A+q7s3KVvt+zQ/ue7K9alsArG/KV6W3aojRgB3Vps6ZzQ1dnKGEgpd7qyc5f2D3xNP3Xqpv0DX9OVnbusXRIApOt+L6L7f0Pu9yLiFhoAecG2H8K0u3EbxRYqIplMii1URLsbt9G2H8KsXdpTy5bOCcHXyoqYkjI1Hdnv/vMW469ekwzD8rxFwi+A3I7HsQHIy8Kr1JfZ0SnFNLOjk8Kr1LdSRbClc0JXZyurE75dO2s3S/EDZZ+YoDq/7pLa1bNiZU+vRz1vMa916bA1dOEEHo1eRLkX1y8gfbEurpmajuxnS+eEFl8r8/ptnxrv3KyCt29KhqGCt2+q8c7N8vptn7VLe2rxvMXciS6cQPp4HFvuxPULyJgidkampiP72dI5ocXXypyLu6niqSOqeOpIyunuxa1UEZyLuyV3c05jOqyHgeCA9HWuVCrFkwIkHseWG3D9AjKma43yWnLwrBL1f4+VdJShrjXKW7Gqp5stnRNafK2MZ/vlPpyT3IkunED6GpZ2U5/qXpYW3mL5HNWnuhfhysq4fgEZ07C0m/rWLJfiGta3ZjmuYVZkS+eEFl8r49l+uQ/nJHcqls8xzX8S6cIJpMTj2HIfrl9AxnENy31s5ZwQfHMBnu2X+3BOch+6cALIq7h+AYD1EXwB5An3P2lkVFQAeQ3XLwCwPoIvgDzDVrraAHj6cP0CAOticCsAAAAAgE0j+AIAAAAAbBrBFwAAAABg0wi+AAAAAACbRvAFAAAAANg0gi8AAAAAwKYRfAEAAAAANo3gCwAAAACwaQRfAAAAAIBNI/gCAAAAAGwawRcAAAAAYNMIvgAAAAAAm0bwBQAAAADYNIIvAAAAAMCmEXwBAAAAADaN4AsAAAAAsGkEXwAAAACATSP4AgAAAABsGsEXAAAAAGDTCL4AAAAAAJtG8AUAAAAA2DSCLwAAAADAphF8AQAAAAA2jeALAAAAALBpBF8AAAAAgE0j+AIAAAAAbBrBFwAAAABg0wi+AAAAAACbRvAFAAAAANg0gi8AAAAAwKYRfAEAAAAANo3gCwAAAACwaQRfAAAAAIBNI/gCAAAAAGwawRcAAAAAYNMIvgAAAAAAm0bwBQAAAADYNIIvAAAAAMCmEXwBAAAAADaN4AsAAAAAsGkEXwAAAACATSP4AgAAAABsGsEXAAAAAGDTCL4AAAAAAJtG8AUAAAAA2DSCLwAAAADAphF8AQAAAAA2jeALAAAAALBpBF8AAAAAgE0j+AIAAAAAbBrBFwAAAABg0wi+AAAAAACb5pBTGzpz5owCAwN18+ZNFSlSRNOmTVO5cuVSzBMcHKzly5fLw8NDklSnTh2NHz9ekhQYGKg9e/aoaNGikiQ/Pz8NHTo0p8oHAAAAAORRORZ8x48fr5dfflkBAQHauHGjxo0bpyVLlqSar1OnTho9enSa6xg8eLB69+6d3aUCAAAAAGxIjnR1vn79uo4cOSJ/f39Jkr+/v44cOaLo6Ogs39atW7cUERGR4uvy5ctZvh0AAAAAQN6QIy2+kZGRKlGihOzt7SVJ9vb28vDwUGRkpIoVK5Zi3s2bN2v37t1yd3fXsGHDVLt2bct7ixYt0qpVq1S2bFmNGDFCFStWTLWtL774QvPmzcveHQIAAAAA5Bk51tU5I3r06KEhQ4bI0dFRP/30k15//XVt2bJFRYsW1TvvvCN3d3fZ2dlpw4YNGjhwoL7//ntLmL6vX79+6ty5c4pply9fVq9evXJyVwAAAAAAuUSOdHX29PRUVFSUzGazJMlsNuvKlSvy9PRMMZ+7u7scHR0lSU2aNJGnp6dOnjwpSSpRooTs7JLL7dSpk+Li4tLswuzq6qoyZcqk+CpZsmR27h4AAAAAIBfLkeDr5uamKlWqKDQ0VJIUGhqqKlWqpOrmHBUVZfn+6NGjunjxosqXL5/qvR9//FF2dnYqUaJEDlQPAAAAAMjLcqyrc1BQkAIDAzV//ny5urpq2rRpkqRBgwZp+PDhql69umbNmqU//vhDdnZ2cnR01PTp0+Xu7i5JGj16tK5fvy6TySQXFxf95z//kYNDruqpDQAAAADIhUyGYRjWLiK7RUREqFWrVtq2bZvKlClj7XIAAAAAAFkovcyXI12dAQAAAACwFoIvAAAAAMCmEXwBAAAAADaN4AsAAAAAsGkEXwAAAACATSP4AgAAAABsGsEXAAAAAGDTCL4AAAAAAJtG8AUAAAAA2DSCLwAAAADAphF8AQAAAAA2jeALAAAAALBpBF8AAAAAgE0j+AIAAAAAbBrBFwAAAABg0wi+AAAAAACbRvAFAAAAANg0gi8AAAAAwKYRfAEAAAAANo3gCwAAAACwaQRfAAAAAIBNI/gCAAAAAGwawRcAAAAAYNMIvgAAAAAAm0bwBQAAAADYNIIvAAAAAMCmEXwBAAAAADaN4AsAAAAAsGkEXwAAAACATSP4AgAAAABsGsEXAAAAAGDTCL4AAAAAAJtG8AUAAAAA2DSCLwAAAADAphF8AQAAAAA2jeALAAAAALBpBF8AAAAAgE0j+AIAAAAAbBrBFwAAAABg0wi+AAAAAACbRvAFAAAAANg0gi8AAAAAwKYRfAEAAAAANo3gCwAAAACwaQRfAAAAAIBNI/gCAAAAAGwawRcAAAAAYNMIvgAAAAAAm0bwBQAAAADYNIIvAAAAAMCmEXwBAAAAADaN4AsAAAAAsGkEXwAAAACATSP4AgAAAABsGsEXAAAAAGDTCL4AAAAAAJtG8AUAAAAA2DSCLwAAAADAphF8AQAAAAA2jeALAAAAALBpGQ6+iYmJ2r9/v7Zs2SJJiouLU1xcXLYVBgAAAABAVnDIyEzHjx/X0KFD5eTkpKioKLVv314///yz1q9fr08++SSbSwQAAAAA4PFlqMU3KChIw4cP1zfffCMHh+SsXL9+ff3yyy/ZWhwAAAAAAE8qQ8H3zz//VEBAgCTJZDJJkgoUKKD4+PjsqwwAAAAAgCyQoeBbunRp/f777ymmHTp0SF5eXtlSFAAAAAAAWSVD9/i+9dZbeu2119SjRw8lJibq008/1cqVKzVp0qTsrg8AAAAAgCeSoRbfli1b6vPPP1d0dLTq16+vixcvKjg4WE2bNs3u+gAAAAAAeCLptviazWa1bdtWW7ZsUVBQUA6UBAAAAABA1km3xdfe3l729vYMZAUAAAAAyJMydI9v37599fbbb+u1115TyZIlLSM7S1LZsmWzrTgAAAAAAJ5UhoLv/UGsfvrppxTTTSaTjh49mvVVAQAAAACQRTIUfI8dO/bEGzpz5owCAwN18+ZNFSlSRNOmTVO5cuVSzBMcHKzly5fLw8NDklSnTh2NHz9eknTnzh2NGTNGf/zxh+zt7TV69Gi1bNnyiesCAAAAANi2DAXf+y5duqSoqCiVLFlSnp6emdrQ+PHj9fLLLysgIEAbN27UuHHjtGTJklTzderUSaNHj041feHChXJxcdF3332ns2fPqlevXvr2229VsGDBTNUBAAAAAHi6ZOhxRleuXFHv3r3Vpk0bDRs2TM8//7x69eqlqKioDG3k+vXrOnLkiPz9/SVJ/v7+OnLkiKKjozNc6NatW9W9e3dJUrly5VStWjXt2rUr1Xy3bt1SREREiq/Lly9neDsAAAAAANuSoRbfoKAgVa5cWSEhISpQoIDi4uI0a9YsjR8/XgsWLEh3+cjISJUoUUL29vaSkkeK9vDwUGRkpIoVK5Zi3s2bN2v37t1yd3fXsGHDVLt2bUnJrc2lS5e2zOfp6ZlmoP3iiy80b968jOwWAAAAAOApkKHg+8svv2jOnDlydHSUJBUoUECjRo3Sc889l6XF9OjRQ0OGDJGjo6N++uknvf7669qyZYuKFi2a4XX069dPnTt3TjHt8uXL6tWrV5bWCgAAADxKYmKiIiIidPfuXWuXAtiMfPnyqUyZMpZsmlEZCr6FCxfWqVOnVLlyZcu006dPy9XVNUMb8fT0VFRUlMxms+zt7WU2m3XlypVU9wm7u7tbvm/SpIk8PT118uRJ+fj4qFSpUrp48aKlhTgyMlINGjRItS1XV9cM1wUAAABkl4iICBUqVEjlypVL8ThQAI/HMAxdv35dERERKl++fKaWzdA9vgMHDtQrr7yimTNnavny5Zo5c6YGDBiggQMHZmgjbm5uqlKlikJDQyVJoaGhqlKlSqpuzn+/Z/jo0aO6ePGiZYf8/Py0atUqSdLZs2d1+PDhLG9xBgAAALLK3bt35ebmRugFsojJZJKbm9tj9aLIUIvvSy+9pLJlyyo0NFTHjx+Xh4eHPv74YzVq1CjDGwoKClJgYKDmz58vV1dXTZs2TZI0aNAgDR8+XNWrV9esWbP0xx9/yM7OTo6Ojpo+fbqlFfjVV19VYGCgnn/+ednZ2WnixIlycXHJ9A4DAAAAOYXQC2Stx/2dMhmGYWRxLblORESEWrVqpW3btqlMmTLWLgcAAABPgaNHj6pKlSrWLgOwOWn9bqWX+TLU1fnNN9/U/v37U0zbv3+/hg8f/gTlAgAAAMgpvr6+OnHiRKrpgwYN0vnz561QUTJfX1/5+fnphRdeULt27bR69Wqr1ZKew4cPa8SIEdYuA48hQ12df/75Z82ZMyfFtFq1aumNN97IlqIAAAAA5IzPPvssx7Z17949OTikjiBz586Vt7e3Tpw4oS5duqhZs2YqUaJEtm7zcVSvXl0ff/xxlqwLOStDPwFOTk66c+dOintq4+LisuwHCAAAAECyKzt36fzSZYq/dl3Oxd3k1aeXPJo3y7bt+fr6asGCBfL29lafPn1UrVo1/fbbb7py5YratWunkSNHJtd15Yo+/PBDXbp0SfHx8erQoYOGDBkiSZo2bZr27dunxMREFS1aVFOmTFHp0qUVERGhrl27qkuXLgoLC9NLL72knj17PrQWb29vubq6KioqSiVKlNDp06c1ZcoU3bhxQ4mJierXr5+6du0qSfrf//6n2bNnK1++fPLz89Ps2bN14MABFSxYUJUqVdKbb76pHTt26LnnntPAgQM1depUHT9+XPHx8WrQoIHGjBkje3t7zZs3T6GhoXJ2dpbJZNKSJUvk6Oio0aNH688//5SDg4PKly+vOXPmKDw8XNOmTdO6deskSRs2bNDChQslSV5eXpo4caLc3Ny0bt06hYaGytXVVSdPnlShQoUUHByc4ik2yFkZSq5NmzbVuHHjLANKxcTEaOLEiYyqDAAAAGShKzt36dS/FygpPl6SFH/1mk79e4EkZWv4/bvIyEgtW7ZMsbGxat26tbp166Zy5cpp9OjRev3111W/fn0lJCTolVdeUfXq1dWkSRMNGjRIo0ePliStXr1aM2fO1OzZsyVJN2/eVPXq1S3vP8ovv/yiokWLqnLlyrp3755GjhypGTNmqGLFioqJiVHXrl1Vq1YtFS5cWOPGjdOqVatUrlw5LV68ONW6nJ2dtXbtWknS+++/r/r162vy5MlKSkrSyJEjtXbtWrVp00aLFy/W7t27lS9fPsXExChfvnz64YcfFBsbqy1btkiS/vrrr1TrP3HihGbOnKl169bJw8NDn3zyiSZNmqRPPvlEUnK36K+//lqenp764IMP9OWXX+qdd955nFOCLJCh4BsYGKj33ntPPj4+Kly4sP766y81a9ZM06dPz+76AAAAgKfG+aXLLKH3vqT4eJ1fuizHgq+fn5/s7OxUqFAhVaxYUefPn5eHh4f27dun6Ohoy3yxsbE6deqUmjRpol27dmn58uWKi4vTvXv3UqzP2dlZ7dq1e+Q2hw8fLsMwdP78ec2ZM0dOTk76888/derUKb377ruW+RITE3X69GnZ2dmpatWqKleunCSpa9eumjp1aop1du7c2fL99u3bdejQIS1atEhS8qOmSpQooUKFCsnLy0ujRo1S06ZN1aJFC7m4uKhy5co6deqUJkyYIB8fH7Vo0SJVzeHh4WrevLk8PDwkST169FBAQIDl/Tp16sjT01OSVLNmTe3Zs+eRxwDZK0PBt3DhwgoJCdHVq1cVGRkpT09PmukBAACALBZ/7XqmpmcHZ2dny/f29vYym81KSkqSyWTSmjVr5OjomGL+ixcvaurUqVqzZo3Kli2rAwcOWLpHS1L+/PnTfQTN/Xt8t27dqjFjxqhOnToyDENFixbVxo0bU82/bdu2dPejQIEClu8Nw9D8+fNVtmzZVPN99dVXOnDggMLCwtSlSxd9/vnnqly5skJDQxUWFqZdu3Zp9uzZ2rRpU7rb/Lu0jiOsJ0OjOkdHRys2Nlbu7u765z//qV27dmnDhg1KSkrK7voAAACAp4ZzcbdMTc8pLi4uqlu3rkJCQizTIiMjdfXqVcXExMjR0VHu7u5KSkrSypUrH3s77dq1U5MmTfTpp5+qfPnyypcvnzZs2GB5/9SpU4qJiVHNmjV15MgRy2jU69evf+R6fX19FRISYgmf0dHRunDhgmJiYhQdHS0fHx8NHz5c3t7eOnnypC5fvix7e3u1bt1aY8aMUXR0tG7evJlinQ0aNNDOnTt19epVSckBunHjxo+978heGWrxfe211zRhwgRVrVpVs2fP1g8//CAHBwcdOXJEY8eOze4aAQAAgKeCV59eKe7xlSQ7Z2d59emVJevv37+/7O3tLa8z04o5c+ZMTZ06VR07dpQkFSxYUJMnT1alSpXk5+en9u3bq2jRomrevHmqR6FmxogRI9SlSxcNGjRICxYs0JQpU7Rw4UIlJSXJzc1Nn3zyiYoXL66goCANGjRI+fPnV4sWLeTo6Kj8+fOnuc6xY8dqxowZCggIkMlkkqOjo8aOHStHR0cNGzZMd+/elWEYqlq1qtq0aaOwsDDL6M1JSUkaPHiwSpQoobNnz1rW6e3trZEjR2rAgAGSpLJly2rixImPvd/IXibDMIz0Zqpfv7727dsnk8mkZs2aaeXKlSpQoID8/f21e/funKjziaT3MGMAAAAgqx09elRVqlTJ9HI5PapzXhUTE2N56szatWu1Zs0arVixwspVISek9buVXubLUIuvnZ2dEhMTdebMGRUqVEilSpVSUlKSYmNjs6ZyAAAAAJKSR28m6KZv6dKl+uabb2Q2m1W4cGF9+OGH1i4JuViGgm+zZs301ltv6ebNm2rfvr0k6c8//8yyh0oDAAAAQGYMHTpUQ4cOtXYZyCMyFHwnT56s9evXy8HBQZ06dZIk3bhxQ8OGDcvO2gAAAAAAeGIZCr5OTk7q3r17imkNGjTIloIAAAAAAMhKGXqcEQAAAAAAeRXBFwAAAABg0wi+AAAAAACbRvAFAAAAngK+vr46ceJElqxr27ZtmjZt2iPnCQ8P1+7duy2vo6Ki1KdPn0xtJzw8XDVr1lRAQID8/f3Vu3dvnTp16rFqzglz5szRli1brF1GnhYcHKyEhIQsX2+GBre6cOGCPvnkEx09elRxcXEp3tuxY0eWFwUAAAA8rXb8ckFLth7VtRt3VLxofvVtV0Ut6pa1dlkptGrVSq1atXrkPPv27VNcXJyaNm0qSSpRooSWLl2a6W1VrFhR69atkyTNmDFDU6dO1eeff575oh/CbDbL3t4+S9b11ltvZcl6bMG9e/fk4JChuJnCvHnzNGDAADk5OWVpPRmqZOTIkSpbtqxGjx6t/PnzZ2kBAAAAAJLt+OWC5q0+qPhEsyTp6o07mrf6oCRlW/jdsGGDFi5cKEny8vLSxIkT5ebmpoSEBE2aNEn79u1TsWLFVKVKFV27dk1z587VunXrtGPHDs2dO1enT5/WmDFjdOfOHSUlJalz585q2rSpVq5cqaSkJO3Zs0cdOnRQ+/bt1bVrV4WHh0uSfv31V02fPl2xsbGSpFGjRllC8sP4+PikaHhbv369li9fLrPZLBcXFwUFBalChQrp1v7111+rYMGCOnfunGbMmKGEhATNnDnTUsvw4cPVokULXb9+XSNGjND169clSY0aNdLYsWN14MABTZo0SUlJSbp3756GDh0qf39/BQYGqlq1aurdu7diY2P14Ycf6vDhw5KkgIAADRo0SJLUp08fVatWTb/99puuXLmidu3aaeTIkWnuc0hIiL7++mtJUvXq1fXBBx+oYMGCCg4O1pkzZ3T79m1duHBBXl5emjNnjvLnz6+EhATNnj1bP//8sxISElSpUiUFBQWpYMGCKdb9/vvvy9vbW/369ZMknThxQkOHDtX333+vr776SosXL5aTk5OSkpL0ySefqGLFio88P5UqVdKbb76pHTt26LnnntPAgQM1depUHT9+XPHx8WrQoIHGjBkje3t7zZs3T6GhoXJ2dpbJZNKSJUs0e/ZsSVKPHj1kZ2enpUuXytXV9ZHbzKgMBd+TJ09qxYoVsrOjZzQAAACQXZZsPWoJvffFJ5q1ZOvRbAm+J06c0MyZM7Vu3Tp5eHjok08+0aRJk/TJJ59o1apVunTpkjZv3iyz2aw+ffqoZMmSqdaxfPly+fr66rXXXpMk/fXXXypcuLB69OihuLg4jR49WpIUERFhWebmzZt68803FRwcrDp16shsNismJuaRtSYlJWnbtm1q3769JGn//v3aunWrli1bJicnJ+3cuVNjx47VypUr06394MGD2rhxo7y8vHTr1i317dtXISEh8vDw0JUrV9StWzeFhoZq06ZN8vLy0uLFiy37JkmfffaZXn31Vfn7+8swDN2+fTtVvfPnz1dSUpI2bdqk2NhYde/eXd7e3mrevLkkKTIyUsuWLVNsbKxat26tbt26qVy5cinWsXPnTn399ddauXKlChYsqNGjR2v+/Pl67733JEm///671qxZo0KFCunVV1/Vpk2b9NJLL+nzzz9XoUKFtGbNGknJLeUhISF65513Uqy/c+fOmjx5siX4rlu3Tp07d5bJZNL06dO1detWeXh4KCEhQWZzyp/Lh3F2dtbatWslJQfr+vXra/LkyUpKStLIkSO1du1atWnTRosXL9bu3buVL18+xcTEKF++fBo/fryWL19u2d+slKHgW79+fR05ckTVqlXL0o0DAAAA+D/XbtzJ1PQnFR4erubNm8vDw0NScktbQECA5b2AgAA5ODjIwcFBHTp00C+//JJqHfXr19eMGTN0584dNWjQQA0bNkx3u7/99psqVqyoOnXqSJLs7e1VuHDhNOc9deqUAgICFBUVJRcXF61evVqStH37dh07dkwvvviiJMkwDN26dStDtdepU0deXl6SklueIyIiLK2xkmQymXTu3DnVrFlTixcv1rRp0+Tj42NpkW7QoIH+85//6Pz582rSpIlq1qyZqu69e/dq7NixMplMcnFxUYcOHbR3715L8PXz85OdnZ0KFSqkihUr6vz586mC7969e9W+fXu5uLhIkl566SVNmTLF8n7Tpk0tLaI1atTQ+fPnLccmJiZG//vf/yRJCQkJqly5cqoa69Wrp9jYWB0/flwVK1ZUaGioVq1aJUlq2LChAgMD1bJlS7Vo0UJly2bsg5fOnTtbvt++fbsOHTqkRYsWSZLu3r2rEiVKqFChQvLy8rK08rdo0cKyj9klQ8G3dOnSGjhwoJ5//nkVL148xXv0YwcAAACyRvGi+XU1jZBbvGjuvd2wbdu2qlWrln766Sd99tlnWrt2rWbOnJll679/j29CQoLeffddBQUFac6cOTIMQ127dn2sPPL31kTDMFSpUiUtW7YszXnXr1+vPXv2aOPGjQoJCdGKFSv0yiuvyNfXV3v27NGkSZPUpEmTVK2p6XF2drZ8b29vn+EW1UetIz4+3rJP48ePV6NGjdJdR6dOnbR+/Xr5+PioYsWKKl26tKTke20PHz6ssLAw9e3bV0FBQZbQ/igFChSwfG8YhubPn59maP7qq6904MABhYWFqUuXLvr888/TDOdZJUN9l+/cuaOWLVvq3r17unz5coovAAAAAFmjb7sqcnZMOdCSs6O9+rarki3ba9CggXbu3KmrV69KSg4jjRs3lpR8P+2mTZt07949xcfHa+vWrWmu49y5c3J3d1eXLl30xhtvWO5pdXFxSbMLsCTVqlVLp06d0q+//iopeYCp+92IH8bJyUlBQUH68ccfdeTIEfn6+mrjxo2WTGI2m/X7779nqnZJql27ts6dO6ewsDDLtEOHDskwDF24cMHSWjtmzBj98ccfSkpK0pkzZ+Tl5aUePXqob9++ln3+u0aNGmnt2rUyDEMxMTHasmWL5dhmVKNGjbR161bFxMTIMAytWbMmQ+vw9fXV4sWLdffuXUlSTEzMQ0fD7tSpk0JDQ7V69Wp16dJFUvLAVBcuXFCNGjU0ePBgNWnSREePHs1U7ffrCAkJsYT66OhoXbhwQTExMYqOjpaPj4+GDx8ub29vnTx5UlLyhxLpdXt/HBlq8Z06dWqWbxgAAABASvfv482uUZ379++fYgTjTZs2aeTIkRowYIAkqWzZspo4caKk5G7Px44dU4cOHVS0aFFVqFAhzXVu3bpVmzZtkqOjo0wmk8aOHStJat26tTZs2KCAgADL4Fb3FSlSRMHBwfroo48UFxcnOzs7jR49Ot1QV7x4cQ0YMEDz5s3T/Pnz9fbbb2vo0KEym81KTEyUn5+fqlWrluHaJalw4cKaP3++ZsyYoSlTpigxMVFly5bVggULtG/fPi1evFh2dnZKSkrShAkTLIMuhYeHy9HRUU5OTvrggw9Srff111/XpEmT1LFjR0nSCy+8oGbNmj1y/x7UvHlzHT9+XD169JAkVatWTUOHDk13ucGDB2vevHnq1q2bTCaTTCaT3nzzzTQHpypVqpSeffZZ7du3T7NmzZKUfD91YGCgbt++LZPJJE9PT40YMUJS8n27vr6+6Y7qLUljx47VjBkzFBAQIJPJJEdHR40dO1aOjo4aNmyY7t69K8MwVLVqVbVp00aSNGDAAPXt21f58uXL0sGtTIZhGBmZ8ezZswoNDdWVK1fk4eEhf3//VH3Qc6uIiAi1atVK27ZtU5kyZaxdDgAAAJ4CR48eVZUq2dNSm1NiYmLk4uKihIQEDR06VH5+fpZ7anO7vFw7Hi2t3630Ml+GWny3b9+ukSNHqmXLlipVqpTOnDmjrl27avr06RlK+gAAAADynv79+yshIUHx8fFq3LhxioGLcru8XDuyXoaC7+zZszV//vwUI7SFh4dr0qRJBF8AAADARt0fQTkvysu1I+tlaHCry5cvq169eimm1a1bl8GtAAAAAAC5XoaCb+XKlfXf//43xbRFixbl+XsWAAAAAAC2L0NdnYOCgjR06FAtWbJEnp6eioyMVP78+bVgwYLsrg8AAAAAgCeSoeBbsWJFbdmyRb/99ptlVOeaNWvK0dExu+sDAAAAAOCJZKirsyQ5ODioXr16at++verVq0foBQAAAPIQX19fnThxIkvWtW3bNk2bNu2R84SHh2v37t2W11FRUerTp0+mthMeHq6aNWsqICBA/v7+6t27t06dOvVYNeeEOXPmaMuWLdYuI5XAwEB9+eWXkrLmvDyJFStWaPHixenO9/eas8JDW3zbtWunrVu3Skp+cLLJZEpzvh07dmRZMQAAAAByv1atWqX7dJd9+/YpLi5OTZs2lSSVKFFCS5cuzfS2KlasqHXr1kmSZsyYoalTp+rzzz/PfNEPYTabZW9vnyXreuutt7JkPdkpq87L4+rZs2eObevvHhp8J02aZPl+xowZOVIMAAAA8LT78dw+rTi0UdfjouVWoJh61gjQc8/4ZNv2NmzYoIULF0qSvLy8NHHiRLm5uSkhIUGTJk3Svn37VKxYMVWpUkXXrl3T3LlztW7dOu3YsUNz587V6dOnNWbMGN25c0dJSUnq3LmzmjZtqpUrVyopKUl79uxRhw4d1L59e3Xt2lXh4eGSpF9//VXTp09XbGysJGnUqFGWMPYwPj4+KRre1q9fr+XLl8tsNsvFxUVBQUGqUKFCurV//fXXKliwoM6dO6cZM2YoISFBM2fOtNQyfPhwtWjRQtevX9eIESN0/fp1SVKjRo00duxYHThwQJMmTVJSUpLu3bunoUOHyt/fX4GBgapWrZp69+6t2NhYffjhhzp8+LAkKSAgQIMGDZIk9enTR9WqVbPcStquXTuNHDky1f6Gh4dr8uTJqlGjhg4ePCgHBwdNnz5d8+bN08mTJ+Xp6ang4GAVKFAgxbYlpXotScePH0/3vFSqVEnvvPOOvvvuO928eVOjRo1S27ZtJUm7du3SrFmzZDabVaxYMU2cOFHPPPNMpuoMDg5WXFycRo8erePHj2vChAm6c+eO4uPj9dJLL+mVV17J+A9vJjw0+P798UU+Ptn3iwYAAAAg2Y/n9unTn5cpwZwgSboWF61Pf14mSdkSfk+cOKGZM2dq3bp18vDw0CeffKJJkybpk08+0apVq3Tp0iVt3rxZZrNZffr0UcmSJVOtY/ny5fL19dVrr70mSfrrr79UuHBh9ejRwxJwJCkiIsKyzM2bN/Xmm28qODhYderUkdlsVkxMzCNrTUpK0rZt29S+fXtJ0v79+7V161YtW7ZMTk5O2rlzp8aOHauVK1emW/vBgwe1ceNGeXl56datW+rbt69CQkLk4eGhK1euqFu3bgoNDdWmTZvk5eVl6Zr7119/SZI+++wzvfrqq/L395dhGLp9+3aqeufPn6+kpCRt2rRJsbGx6t69u7y9vdW8eXNJUmRkpJYtW6bY2Fi1bt1a3bp1U7ly5VKt59SpU5o2bZo+/PBDTZgwQa+++qq++uorlSxZUoMGDdLmzZv14osvPvLY3VepUqVHnpf7XFxctHbtWv3yyy96++231bZtW12/fl2jRo3Sl19+qWeffVarV6/WyJEjLc9Lfpw6S5curcWLF8vJyUmxsbF68cUX9dxzz6lixYoZ2p/MyNDgVosWLVLDhg1VpUoV/fbbb3r77bdlZ2enjz/+WLVr187yogAAAICn0YpDGy2h974Ec4JWHNqYLcE3PDxczZs3l4eHhySpR48eCggIsLwXEBAgBwcHOTg4qEOHDvrll19SraN+/fqaMWOG7ty5owYNGqhhw4bpbve3335TxYoVVadOHUmSvb29ChcunOa8p06dUkBAgKKiouTi4mIJWtu3b9exY8csYcowDN26dStDtdepU0deXl6SklueIyIiLK2xkmQymXTu3DnVrFlTixcv1rRp0+Tj42NpkW7QoIH+85//6Pz582rSpIlq1qyZqu69e/dq7NixMplMcnFxUYcOHbR3715L8PXz85OdnZ0KFSqkihUr6vz582kG3/Lly1seI1u1alVdunTJEuL/+c9/6ty5c+ke78y6/+FCrVq1dOXKFcXHx+vgwYOqXLmynn32WUlS165dNWHCBMsHFo9T5927dxUUFKTjx4/LZDLpypUrOnbsmPWC7+LFi9WtWzdJ0scff6xXXnlFBQsW1JQpUyw/eAAAAACezPW46ExNzw3atm2rWrVq6aefftJnn32mtWvXaubMmVm2/vv3+CYkJOjdd99VUFCQ5syZI8Mw1LVr18e6r7ZgwYKW7w3DUKVKlbRs2bI0512/fr327NmjjRs3KiQkRCtWrNArr7wiX19f7dmzR5MmTVKTJk30zjvvZKoGZ2dny/f29vYym81pzufk5JRivgeXi4+Pt3yflJRkee/+9Mdxfxv3732+d+9eustktM6/mzVrltzd3fXRRx/JwcFBAwYMeKK6HyVDozrfvn1bhQoVUkxMjI4fP64+ffroxRdf1JkzZ7KlKAAAAOBp5FagWKamP6kGDRpo586dunr1qiTpq6++UuPGjSUl3+64adMm3bt3T/Hx8ZaBbx907tw5ubu7q0uXLnrjjTcs97S6uLik2QVYSm5JPHXqlH799VdJyQNM3e9G/DBOTk4KCgrSjz/+qCNHjsjX11cbN27U5cuXLev4/fffM1W7JNWuXVvnzp1TWFiYZdqhQ4dkGIYuXLhgaa0dM2aM/vjjDyUlJenMmTPy8vJSjx491LdvX8s+/12jRo20du1aGYahmJgYbdmyxXJss8MzzzxjqePKlSuWe3Yf9Kjz8ii1atXSsWPHLKNqr1+/XlWrVpWLi8tj13z79m2VLFlSDg4OOnHihPbv3//Y60pPhlp8PT09deDAAf3555+qV6+e7O3tFRMTk2WjnwEAAACQetYISHGPryQ52TupZ42ALFl///79U/wPv2nTJo0cOVIDBgyQJJUtW1YTJ06UlNzt+dixY+rQoYOKFi2qChUqpLnOrVu3atOmTXJ0dJTJZNLYsWMlSa1bt9aGDRsUEBBgGUTpviJFiig4OFgfffSR4uLiZGdnp9GjR6cbDIsXL64BAwZo3rx5mj9/vt5++20NHTpUZrNZiYmJ8vPzU7Vq1TJcuyQVLlxY8+fP14wZMzRlyhQlJiaqbNmyWrBggfbt26fFixfLzs5OSUlJmjBhguzs7LR06VKFh4fL0dFRTk5O+uCDD1Kt9/XXX9ekSZPUsWNHSdILL7ygZs2aPXL/nsSLL76o4cOHq3379ipXrpxq1KiR5nyPOi+PUqxYMU2fPl0jR47UvXv3VKxYsSceBHno0KEaNWqU1qxZo/Lly6t+/fpPtL5HMRmGYaQ3086dO/X+++/LyclJc+fOVbVq1bRp0yZt3LgxS4cSzy4RERFq1aqVtm3bpjJlyli7HAAAADwFjh49arnnMTNyelTnR4mJiZGLi4sSEhI0dOhQ+fn5ZXggJWvLy7Xj0dL63Uov82Woxbd58+YpHnIsJd+M7efn9wTlAgAAAHjQc8/4WC3oPqh///5KSEhQfHy8GjdurM6dO1u7pAzLy7Uj62Uo+P75558qUqSIihcvrtjYWC1cuFB2dnZ69dVX5ejomN01AgAAALCCvDyQbV6uHVkvQ4Nbvfvuu5ahwadNm6aff/5Zv/32m8aNG5etxQEAAAAA8KQy1OJ78eJFVahQQYZh6LvvvtPmzZuVL18+tWrVKrvrAwAAAADgiWQo+Do7OysmJkanTp2Sp6enihUrZhkaHAAAAACA3CxDwdff31/9+vVTbGysevfuLUk6cuQIIyQDAAAAAHK9DAXfsWPHavfu3XJwcFDDhg0lSSaTSWPGjMnW4gAAAAAAeFIZGtxKkpo2bapnnnlGv/32mySpevXqatSoUXbVBQAAACALJSQk6KOPPlLr1q3l5+enTp066fvvv8/UOipVqqTY2NhsqjCZr6+vTpw4kWp6eHi4unTpkmXbef/997V///5HzrN48WJdv37d8nrFihVavHhxprYTGBioZs2aKSAgQG3bttWkSZOUlJT0OCXniICAAN29e9faZWS5DLX4Xrp0Se+++66OHTsmk8mkX3/9Vd98841+/PFHTZ48ObtrBAAAAJ4aYReva/3xS4q+m6hi+RzVuVIpNSzt9sTrDQoKUlxcnDZv3ixnZ2edOHFCAwcOVOHChVW/fv1U85vNZtnb2z/xdu/duycHhwzFjhyVkRyzZMkSNW7cWG5uyce/Z8+ej7WtwYMHq3fv3oqJiVHnzp1Vt25dtW/f/rHW9aCsPr4bN27MsnXlJhk6QuPGjVOLFi20fPlyNWjQQJLUpEkTTZs2LVuLAwAAAJ4mYReva+nh80pIMiRJ0XcTtfTweUl6ovB78eJFbd26VT/88IOcnZ0lSd7e3hoyZIjmzZunL774QuvWrdPXX3+tggUL6ty5c5oxY4YuXLigWbNmydnZWW3atEmxzoMHD2rmzJmWFuDhw4erRYsWioiIUNeuXdWlSxeFhYXppZdeUqtWrfThhx/q0qVLio+PV4cOHTRkyBBJ0v79+zVhwgRJUv369WUYRqb2LTY2Vh9++KEOHz4sKbnFctCgQZKkP//8U2PGjNGdO3dUuXJlnT9/XkOHDlXLli3Vp08fDRgwQC1bttSqVau0ePFiOTk5KSkpSZ988om+/fZbXblyRcOHD5ezs7M+/vhjbd26VXFxcRo9erQk6dNPP1VoaKhMJpMKFCig5cuXy87u4Z1qXVxc9M9//lOXLl2SJMXExGjq1Kk6fvy44uPj1aBBA40ZM0b29vbp1l65cmUdPHhQhQsX1meffaaQkBB9++23MpvNKlGihCZNmiR3d3d9//33mjNnjuzs7GQ2m/Wvf/1LDRo00Lx58xQaGipnZ2eZTCYtWbJErq6uqlSpkg4cOKCCBQvq0KFDmjx5suLi4lSgQAG9//77qlGjhuUc9+jRQzt37tSdO3c0efJk1atXL1PnLidlKPgePnxYISEhsrOzk8lkkiQVKlRIt2/fztbiAAAAgKfJ+uOXLKH3voQkQ+uPX3qi4HvixAl5eXmpSJEiKabXqlVLc+bMsbw+ePCgNm7cKC8vL127dk2vvPKKVqxYoQoVKuizzz6zzHfr1i2NHz9eISEh8vDw0JUrV9StWzeFhoZKkm7evKnq1atbAmL//v31+uuvq379+kpISNArr7yi6tWrq379+nrnnXc0c+ZMNWjQQFu2bNGyZcsytW/z589XUlKSNm3apNjYWHXv3l3e3t5q3ry5Ro0apX79+ikgIECHDx/WSy+9lOY6pk+frq1bt8rDw0MJCQkym80aOnSoVq9erblz58rb2zvVMuvXr9f27du1YsUKubi46MaNG48MvZJ0/fp1HT9+XMOGDZMkTZ06VfXr19fkyZOVlJSkkSNHau3atXrppZfSrf3ChQtavny5HBwctHHjRl24cEFfffWV7OzstHz5cn300Uf6+OOPNXfuXE2cOFG1a9eW2WzWnTt3dPPmTS1evFi7d+9Wvnz5FBMTo3z58qVYf0JCgoYPH66pU6eqUaNG2rNnj4YPH65vv/1WUvI5rlWrlt555x19/fXXmjlzplauXJnh85bTMhR83dzcdO7cOZUvX94y7c8//5Snp2e2FQYAAAA8baLvJmZqekZltBW1Tp068vLykpQcgqtWraoKFSpIkrp3766ZM2dKkn799VdFRERYWlal5MFvz507p6JFi8rZ2Vnt2rWTJMXFxWnfvn2Kjo62zBsbG6tTp07Jzc1N+fPnt/Qqbd++vcaNG5epfdu7d6/Gjh0rk8kkFxcXdejQQXv37lXdunV14sQJdezYUVLyGEWVKlVKcx0NGzZUYGCgWrZsqRYtWqhs2bLpbveHH35Qz5495eLiIkkqWrToQ+cNCQnRqlWrdObMGfXs2VMVK1aUJG3fvl2HDh3SokWLJEl3795ViRIlFBMTk27tHTt2tHRx3r59u37//Xd17txZUnI39ft1NWzYUFOnTlWbNm3UrFkzeXt7y2w2y8vLS6NGjVLTpk3VokULy/z3nTlzRo6OjpZxnRo3bixHR0edOXNGBQsWVIECBdSyZUtJyR+g5PbewBkKvgMGDNCQIUM0ePBg3bt3T6Ghofr0009T/KADAAAAeDLF8jmmGXKL5XN8ovV6e3vr/PnzunnzZopW399++y1FoCpYsGCG1mcYhipVqpRm62xERITy589v6SmalJQkk8mkNWvWyNEx5X4cO3Ys1fL3l8sqGVnfvHnzdPjwYYWFhalv374KCgpS8+bNs6yG+/f4nj59Wj179lTTpk3VvHlzGYah+fPnpwraMTEx6dZeoEABy/eGYWjo0KHq1q1bqvnGjh2r48ePKywsTG+99Zb69++vl156SV999ZUOHDigsLAwdenSRZ9//rkqV66c4X1ycnKyfG9nZ6d79+5leFlryNCozt26ddN7772nb775Rp6entqwYYPeeustvfDCC9ldHwAAAPDU6FyplJzsUoYdJzuTOlcq9UTrLVOmjPz8/BQUFKT4+HhJyd2fFyxYoDfffDPNZWrVqqUjR47o7NmzkqTVq1db3qtdu7bOnTunsLAwy7RDhw6l2bLs4uKiunXrKiQkxDItMjJSV69eVYUKFXT37l3L6MrffPONbt26lal9a9SokdauXSvDMBQTE6MtW7aocePGcnFx0T/+8Q9L9+s//vgjzdGi7927pwsXLqhGjRoaPHiwmjRpoqNHj0pK/iDgYbd3tmzZUitWrLCE1Bs3bqRba4UKFTR8+HDNnj1bhmHI19dXISEhMpvNkqTo6GhduHAhw7Xf5+vrq+XLl+uvv/6SlNxN+f6HCqdPn1alSpXUr18/vfDCCzp8+LBiYmIUHR0tHx8fDR8+XN7e3jp58mSKdZYvX16JiYmWc7x3717du3cvRS/gvCTdFl+z2axXXnlFCxcuVOvWrXOiJgAAAOCpdP8+3uwY1Xn8+PGaNWuW2rdvL0dHRzk7O+v999+Xj49PmvO7ublp0qRJGjJkiPLly5dicKvChQtr/vz5mjFjhqZMmaLExESVLVtWCxYsSHNdM2fO1NSpUy1ddwsWLKjJkyfL3d1ds2bNSjG4ValSDw/5J06cULNmzSyvGzdurH/961+aNGmSZd0vvPCCZZ5p06Zp7NixCgkJkbe3t7y9vVWoUKEU60xKSlJgYKBu374tk8kkT09PjRgxQpLUt29fjR07Vvny5dPHH3+cYrlOnTopKipK3bt3l4ODgwoUKKBly5ale59v9+7dtWTJEm3btk1jx47VjBkzFBAQIJPJJEdHR40dO1Zly5bNUO1/r+XmzZvq3bu3pOQW4J49e6py5cr6+OOPde7cOdnb28vV1VWTJ09WTEyMhg0bprt378owDFWtWjXV4GVOTk6aO3duisGt5syZk6KlNy8xGRno8N+yZUtt3bo11Q3PeUVERIRatWqlbdu2qUyZMtYuBwAAAE+Bo0ePqkqVKtYu46kWGxurAgUKyGQy6c8//1SfPn30zTffqHDhwtYuLV15ufbsltbvVnqZL0P3+L7xxhsKCgrSsGHDVLJkyRR9zdP7RAMAAAAArOHXX3/V9OnTLV2wJ02alGeCY16uPTfKUPD94IMPJKV8mLFhGDKZTJb+7wAAAACQmzRt2lRNmza1dhmPJS/XnhtlKPhu27Ytu+sAAAAAbM79xiIAWSOjj+Z6UIaCb+nSpR9r5QAAAMDTyt7eXomJiXl2MCAgN0pMTLQ8vzgzMrTEe++9l+YnVU5OTipZsqRat26dqWc+AQAAALauSJEiioqKUunSpRkXB8gCSUlJioqKeqx7nTMUfAsVKqSNGzfK19dXnp6eioyM1A8//KD27dvr1KlT+uyzzzRhwgR16tQp0wUAAAAAtqh48eKKiIjQ8ePHrV0KYDMKFiyo4sWLZ3q5DAXfs2fPKiQkRHXr1rVM+/XXXzV37lwtWrRIu3bt0pQpUwi+AAAAwP9nZ2cnLy8va5cBQFKG+lwcPHhQNWvWTDGtWrVqOnTokCTpueeeU1RUVNZXBwAAAADAE8pQ8K1SpYpmz56t+Ph4SVJ8fLzmzJljua83IiKCZ0oBAAAAAHKlDHV1/uijjzRy5EjVrVtXhQsX1l9//aVq1appxowZkqSbN29q/Pjx2VooAAAAAACPI0PBt0yZMlq5cqUiIyN15coVubu7q1SpUpb3q1evnm0FAgAAAADwJDI8rvqNGzcUHh6uffv2qVSpUoqKitLly5ezszYAAAAAAJ5YhoLvvn375Ofnp02bNmn+/PmSpHPnzikoKCg7awMAAAAA4IllKPhOmTJFn3zyiRYuXCgHh+Te0TVr1rSM6gwAAAAAQG6VoeB78eJFNWrUSJJkMpkkSY6OjjKbzdlXGQAAAAAAWSBDwbdixYr68ccfU0zbs2ePvL29M7yhM2fOqHv37mrbtq26d++us2fPPnTe06dPq2bNmpo2bZplWmBgoJo1a6aAgAAFBAToP//5T4a3DQAAAAB4emVoVOfAwEC99tpratGihe7evatx48Zp+/btlvt9M2L8+PF6+eWXFRAQoI0bN2rcuHFasmRJqvnMZrPGjx+v1q1bp3pv8ODB6t27d4a3CQAAAABAhlp8a9Sooa+//lrPPvusunbtqjJlymjNmjWqUaNGhjZy/fp1HTlyRP7+/pIkf39/HTlyRNHR0anmDQkJUYsWLVSuXLmM78Xf3Lp1SxERESm+GH0aAAAAAJ5e6bb4ms1m1a5dW/v379egQYMeayORkZEqUaKE7O3tJUn29vby8PBQZGSkihUrZpnv2LFj2r17t5YsWZJma/KiRYu0atUqlS1bViNGjFDFihVTzfPFF19o3rx5j1UnAAAAAMD2pBt87e3tVa5cOd24cUMlSpTItkISExP1r3/9S1OnTrUE5L9755135O7uLjs7O23YsEEDBw7U999/n2refv36qXPnzimmXb58Wb169cq22gEAAAAAuVeG7vHt2LGjhgwZor59+6pkyZIp3rs/2vOjeHp6KioqSmazWfb29jKbzbpy5Yo8PT0t81y9elXnz5/X4MGDJSV3WTYMQzExMZo0aVKK0N2pUydNnTpVly9fVunSpVNsy9XVVa6urhnZLQAAAADAUyBDwXfFihWSpODg4BTTTSaTtm3blu7ybm5uqlKlikJDQxUQEKDQ0FBVqVIlRTfnUqVKKTw83PI6ODhYcXFxGj16tCQpKirKEn5//PFH2dnZZWsLNAAAAADANmQo+G7fvv2JNxQUFKTAwEDNnz9frq6ulkcVDRo0SMOHD1f16tUfufzo0aN1/fp1mUwmubi46D//+Y8cHDJUPgAAAADgKWYyDMOwdhHZLSIiQq1atdK2bdtUpkwZa5cDAAAAAMhC6WW+DD3OCAAAAACAvIrgCwAAAACwaQRfAAAAAIBNY3QoAAAAAECadvxyQUu2HtW1G3dUvGh+9W1XRS3qlrV2WZlG8AUAAAAApLLjlwuat/qg4hPNkqSrN+5o3uqDkpTnwi9dnQEAAAAAqSzZetQSeu+LTzRrydajVqro8RF8AQAAAACpXLtxJ1PTczOCLwAAAAAgleJF82dqem7GPb4A8gxbGVwBAAAgL+jbrkqKe3wlydnRXn3bVbFiVY+H4AsgT7ClwRUAAADygvv/Y9lCwwPBF0Ce8KjBFfLixRcAACAvaFG3rE38r8U9vgDyBFsaXAEAAAA5i+ALIE+wpcEVAAAAkLMIvgDyhL7tqsjZ0T7FtLw6uAIAAAByFvf4AsgTbGlwBQAAAOQsgi+APMNWBlcAAFgfj8gDni4EXwAAADxVeEQe8PThHl8AAAA8VR71iDwAtokWXwAAgGxGt9rchUfkAU8fWnwBAACy0f1utVdv3JGh/+tWu+OXC9Yu7anFI/KApw/BFwAAIBvRrTb34RF5udeOXy5owIff6oURGzXgw2/5gAhZhq7OAAAA2YhutbkPj8jLnRh0DNmJ4AsAAJCNihfNr6tphFy61VoXj8jLfR7VO4JzhSdFV2cAAIBsRLdaIGPoHYHsRIsvkAZG3wSQV3H9yn3oVgtkDL0jkJ0IvsADuL8EQF7F9Sv3olstkL6+7aqkuIZJ9I5A1qGrM/AARt8EkFdx/QKQl7WoW1ZvvlhT7kXzyyTJvWh+vfliTT40QpagxRd4APeXAMiruH4ByOvoHYHsQosv8AAeag8gr+L6BQBA2gi+wAMYfRNAXsX1CwCAtNHVGXgAo28CGccIwrkL1y8AANJG8AXSwP0lQPoYQTh34voFAEBqdHUGADwWRhAGAAB5BcEXAPBYGEEYAADkFQRfAMBjYQRhAACQVxB8AQCPhRGEAQBAXsHgVgCAx8IIwgAAIK8g+AIAHhsjCAMAgLyArs4AAAAAAJtG8AUAAAAA2DSCLwAAAADAphF8AQAAAAA2jeALAAAAALBpBF8AAAAAgE0j+AIAAAAAbBrBFwAAAABg0wi+AAAAAACbRvAFAAAAANg0gi8AAAAAwKYRfAEAAAAANo3gCwAAAACwaQRfAAAAAIBNI/gCAAAAAGwawRcAAAAAYNMIvgAAAAAAm0bwBQAAAADYNIIvAAAAAMCmEXwBAAAAADaN4AsAAAAAsGkEXwAAAACATXOwdgGQdvxyQUu2HtW1G3dUvGh+9W1XRS3qlrV2WQAAAABgEwi+Vrbjlwuat/qg4hPNkqSrN+5o3uqDkkT4BQAAAIAsQFdnK1uy9agl9N4Xn2jWkq1HrVQRAAAAANgWgq+VXbtxJ1PTAQAAAACZQ/C1suJF82dqOgAAAAAgcwi+Vta3XRU5O9qnmObsaK++7apYqSIAAAAAsC0MbmVl9wewYlRnAAAAAMgeBN9coEXdsgRdAAAAAMgmdHUGAAAAANg0gi8AAAAAwKblWPA9c+aMunfvrrZt26p79+46e/bsQ+c9ffq0atasqWnTplmm3blzR2+//baef/55+fn56YcffsiBqgEAAAAAeV2OBd/x48fr5Zdf1v/+9z+9/PLLGjduXJrzmc1mjR8/Xq1bt04xfeHChXJxcdF3332nBQsW6IMPPlBsbGxOlA4AAAAAyMNyJPhev35dR44ckb+/vyTJ399fR44cUXR0dKp5Q0JC1KJFC5UrVy7F9K1bt6p79+6SpHLlyqlatWratWtXttcOAAAAAMjbciT4RkZGqkSJErK3T35erb29vTw8PBQZGZlivmPHjmn37t165ZVXUq3j0qVLKl26tOW1p6enLl++nGq+W7duKSIiIsVXWvMBAAAAAJ4OueZxRomJifrXv/6lqVOnWgLy4/jiiy80b968LKwMAAAAAJCX5Ujw9fT0VFRUlMxms+zt7WU2m3XlyhV5enpa5rl69arOnz+vwYMHS0puuTUMQzExMZo0aZJKlSqlixcvqlixYpKSW5EbNGiQalv9+vVT586dU0y7fPmyevXqlY17CAAAAADIrXIk+Lq5ualKlSoKDQ1VQECAQkNDVaVKFUuIlaRSpUopPDzc8jo4OFhxcXEaPXq0JMnPz0+rVq1S9erVdfbsWR0+fFgff/xxqm25urrK1dU1+3cKAAAAAJAn5NiozkFBQfryyy/Vtm1bffnll5owYYIkadCgQTp8+HC6y7/66qu6deuWnn/+eb322muaOHGiXFxcsrtsAAAAAEAeZzIMw7B2EdktIiJCrVq10rZt21SmTBlrlwMAAAAAyELpZb4ca/EFAAAAAMAaCL4AAAAAAJtG8AUAAAAA2DSCLwAAAADAphF8AQAAAAA2jeALAAAAALBpBF8AAAAAgE0j+AIAAAAAbJqDtQsAAAAAAOROP57bpxWHNup6XLTcChRTzxoBeu4ZH2uXlWkEXwAAAABAKj+e26dPf16mBHOCJOlaXLQ+/XmZJOW58EtXZwAAAABAKisObbSE3vsSzAlacWijlSp6fARfAAAAAEAq1+OiMzU9NyP4AgAAAABScStQLFPTczOCLwAAAAAglZ41AuRk75RimpO9k3rWCLBSRY+Pwa0AAAAAAKncH8CKUZ0BAAAAADbruWd88mTQfRDBFwAAAECuYCvPjEXuQ/AFAAAAYHW29MxY5D4MbgUAAADA6mzpmbHIfQi+AAAAAKzOlp4Zi9yH4AsAAADA6mzpmbHIfQi+AAAAAKzOlp4Zi9yHwa0AAAAAWJ0tPTMWuQ/BFwAAAECuYCvPjEXuQ1dnAAAAAIBNI/gCAAAAAGwawRcAAAAAYNMIvgAAAAAAm0bwBQAAAADYNIIvAAAAAMCmEXwBAAAAADaN4AsAAAAAsGkEXwAAAACATSP4AgAAAABsGsEXAAAAAGDTHKxdAKQfz+3TikMbdT0uWm4FiqlnjQA994yPtcsCAAAAAJtA8LWyH8/t06c/L1OCOUGSdC0uWp/+vEySCL8AAAAAkAXo6mxlKw5ttITe+xLMCVpxaKOVKgIAAAAA20LwtbLrcdGZmg4AAAAAyByCr5W5FSiWqekAAAAAgMzhHl8r61kjIMU9vpLkZO+knjUCrFgVkDsxEBwAAAAeB8HXyu7/084/88CjMRAcAAAAHhfBNxd47hkf/nEH0vGogeD4/QEAAMCjcI8vgDyBgeAAAADwuAi+APIEBoIDAADA4yL4AsgTetYIkJO9U4ppDAQHAACAjOAeXwB5AgPBAQCyEk8KAJ4uBF8AeQYDwQEAsgJPCgCePgRfIA18CgwAgO3iSQHA04fgCzyAT4EBALBtPCkAePowuBXwgEd9CgwAAPI+nhQAPH0IvsAD+BQYAADbxpMCgKcPXZ2BB7gVKKZraYRcPgUGAMA28KQA4OlD8AUe0LNGQIp7fCU+BQYAwNbwpADg6ULwBR7Ap8AAAACAbSH4AmngU2AAAADAdhB8AQAAshnPhwcA6yL4AgAAZCOeDw8A1sfjjAAAALIRz4cHAOujxRcA8Njovgmkj+fDA4D10eILAHgs97tvXouLlqH/677547l91i4NyFUe9hx4ng8PADmH4AsAeCx03wQypmeNADnZO6WYxvPhASBn0dUZAPBY6L4JZAzPhwcA6yP4AgAei1uBYrqWRsil+yaQGs+HBwDrIvgCAB5LzxoBKR7RItF9MzdgwDEAAFIj+AIAHgvdN3MfnhcLAEDaCL4AgMdG983c5VEDjnGeAABPM0Z1BgDARjDgGAAAaSP4AgBgI3heLAAAaSP4AgBgI3heLAAAaeMeXwAAbAQDjgEAkLYcC75nzpxRYGCgbt68qSJFimjatGkqV65cinnWrl2rxYsXy87OTklJSXrxxRfVt29fSVJwcLCWL18uDw8PSVKdOnU0fvz4nCofAIA8gQHHAABILceC7/jx4/Xyyy8rICBAGzdu1Lhx47RkyZIU87Rt21ZdunSRyWRSTEyMOnbsKB8fH1WuXFmS1KlTJ40ePTqnSgYAAAAA2IAcucf3+vXrOnLkiPz9/SVJ/v7+OnLkiKKjU44y6eLiIpPJJEm6e/euEhMTLa8z6tatW4qIiEjxdfny5azZEQAAAABAnpMjLb6RkZEqUaKE7O3tJUn29vby8PBQZGSkihVLOdLktm3bNGvWLJ0/f14jRoxQpUqVLO9t3rxZu3fvlru7u4YNG6batWun2tYXX3yhefPmZe8OAQAAAADyjFw3uFWrVq3UqlUrXbp0SW+88YaaNWumChUqqEePHhoyZIgcHR31008/6fXXX9eWLVtUtGjRFMv369dPnTt3TjHt8uXL6tWrV07uBgAAAAAgl8iR4Ovp6amoqCiZzWbZ29vLbDbrypUr8vT0fOgypUqVUvXq1bVjxw5VqFBB7u7ulveaNGkiT09PnTx5Uj4+KQfwcHV1laura7btCwAAAAAgb8mRe3zd3NxUpUoVhYaGSpJCQ0NVpUqVVN2cT506Zfk+Ojpa4eHh8vb2liRFRUVZ3jt69KguXryo8uXL50D1AAAAAIC8LMe6OgcFBSkwMFDz58+Xq6urpk2bJkkaNGiQhg8frurVq2vVqlX66aef5ODgIMMw1Lt3bzVt2lSSNGvWLP3xxx+ys7OTo6Ojpk+fnqIVGAAAAACAtJgMwzCsXUR2i4iIUKtWrbRt2zaVKVPG2uUAAAAAALJQepkvR7o6AwAAAABgLQRfAAAAAIBNI/gCAAAAAGwawRcAAAAAYNMIvgAAAAAAm5ZjjzOyJrPZLEm6fPmylSsBAAAAAGS1+1nvfvZ70FMRfK9evSpJ6tWrl5UrAQAAAABkl6tXr+qZZ55JNf2peI7v3bt39fvvv8vd3V329vbWLidNly9fVq9evbRs2TKVLFnS2uVAnJPcivOS+3BOch/OSe7Eecl9OCe5E+cl98kL58RsNuvq1auqVq2a8uXLl+r9p6LFN1++fKpXr561y8iQkiVLpvnAZVgP5yR34rzkPpyT3IdzkjtxXnIfzknuxHnJfXL7OUmrpfc+BrcCAAAAANg0gi8AAAAAwKYRfAEAAAAANo3gm0u4urrqzTfflKurq7VLwf/HOcmdOC+5D+ck9+Gc5E6cl9yHc5I7cV5yH1s4J0/FqM4AAAAAgKcXLb4AAAAAAJtG8AUAAAAA2DSCLwAAAADAphF8s0GlSpUUGxv7yHmWL18uPz8/derUSTExMY+1neDgYE2bNk2SdPToUW3ZsuWx1oNHW7dunYYPH55jy+Ul1jw2+/fvz5HjGxERoVWrVqWY5uvrqxMnTkiS3n//fe3fvz/b68iMv9eXlW7cuKEePXooICBAn3/+eZav/0GLFy/W9evXs307acnIdfxxhIeHq0uXLlm6zuDgYCUkJFheBwYG6ssvv5QkrVixQosXL86S7YwZM0YdOnTQ22+//VjLh4eHa/fu3VlSi62LiIhQgwYNrF2G1SUkJOijjz5S69atLf8zff/99xle/tChQ+rfv79at26trl27qm/fvvr555/TXW7r1q3q1KmTAgIC5OfnpxEjRkiSBg4cqBUrVqSY1zAMtWrVSvv27dO6detUqVIlLVu2LNX7efF8+vr6ys/PTy+88IL8/f21efNmy3sTJkxQQECAAgICVK1aNfn5+Vlem81mK1b9f/5+LXyUs2fPqlOnTurUqZO+/vrrHKgsY/L68c+MnPp/0iHTW0CWWLp0qaZPn64aNWpkyfqOHj2qHTt2qH379lmyPiC327Ztm1q1apXt27l48aJWrVql7t27p/n+5MmTM73Oe/fuycEh711+9+7dK1dXV61cuTJTyz3u/i5ZskSNGzeWm5tbppd9msybN08DBgyQk5NTqvd69uyZ6fUlJSXJZDLJZDJZpl27dk3/+9//tH//ftnZPd5n5vv27VNcXJyaNm2a6WXNZrPs7e0fa7vIu4KCghQXF6fNmzfL2dlZJ06c0MCBA1W4cGHVr1//kcseP35cr732mqZPn67nnntOknT+/HkdPXr0kctduXJFEyZM0Pr16+Xp6SnDMCzLdO3aVYsWLUrxexUeHi47OzvVr19fERERqlq1qjZs2KBevXpZ3i9cuPBjN3JY29y5c+Xt7a0jR46oR48eatSokYoVK6bx48db5vH19bXM93d55W/dt99+q9q1a6fYp9ziaTj+OYmjkQW+/fZbzZo1S87OzmrTpo1l+sGDBzVz5kxLq8Hw4cPVokULvf3227pw4YJGjRqlf/7zn5o2bZpee+013bhxQ/Hx8apRo4YmTJggJycnBQcHKy4uTqNHj5akVK+l5FaYuXPnKiYmRgEBAapfv74++OCDnD0IudCdO3c0evRo/fnnn3JwcFD58uU1Z84crVmzRkuWLJEkOTo66tNPP1WRIkUeeg4etH79ei1fvlxms1kuLi4KCgpShQoVlJCQoA8//FBhYWEqWrSoqlSpktO7nCEPOy6SrH5sfvzxRy1dulQhISG6fv26mjRpotmzZ6tdu3b67LPPdPv2bb377ruSpB07dmjIkCGSpA0bNmjhwoWSJC8vL02cODHNsHTo0CFNnjxZcXFxKlCggN5//33VqFFD4eHhmjZtmtatWydJKV5PnDhRERERCggI0DPPPKO5c+emWGefPn00YMAAtWzZUjExMZo6daqOHz+u+Ph4NWjQQGPGjJG9vb369OmjypUr6+DBgypcuLA+++yzxzl9mTZv3jyFhobK2dlZJpNJS5Yskaurq3bt2qVZs2bJbDarWLFimjhxop555pmHricsLEzTp0+3XGf+9a9/qVy5cho/frzOnz8vSXr11VfVqVMnScl/iNu3b6+wsDB5e3srKChIs2fP1s8//6yEhARVqlRJQUFBKliwoFatWqXFixfLyclJSUlJ+uSTT/Ttt9/qypUrGj58uJydnfXxxx/r7NmzmjNnjuzs7GQ2m/Wvf/0rR1pRHvZzI0k//PCDgoODde/ePdnZ2emjjz5S5cqVNWLECJ05c0aJiYny8vLSlClTVLhw4Udu59q1aw89npUqVdKBAwdUsGDBFK9nzpwpSerRo4fs7Oy0dOnSFOt88G9GSEiIvv32W5nNZpUoUUKTJk2Su7u7goODdfLkScXExOjSpUtatWqVpd6YmBj17dtXd+/eVefOndW5c2f16dNHM2fO1I8//ihJeu655zRy5EjZ29vr9u3bmjJlin7//XeZTCbVq1dP3bt318qVK5WUlKQ9e/aoQ4cOGjx48EN/d9etW6evv/5aBQsW1Llz5zRjxoxce02Vks/H22+/re+//143b97Uhx9+qD179ujHH3/UvXv3NGfOHFWsWFFS2tfZ4sWLa9myZVq8eLFcXFzUvHlza+5OrnDx4kVt3bpVP/zwg5ydnSVJ3t7eGjJkiObNm6cvvvjikct/9tln6tatmyX0Ssk/Y15eXo9c7tq1a3JwcFCRIkUkSSaTSVWrVpUktWrVSkFBQTp16pTlfK5bt05dunSxfFBUtmxZ3bhxQ3/++aeeffZZrV+/Xp07d9a8efMe6zjkFlWrVlXBggUVERGhYsWKPXS+wMBA2dvb68yZM4qNjdXGjRsfej0MDw/XlClTVLNmTf36668ymUyaPXu2KlasqNOnT2vMmDG6c+eOkpKS1LlzZ7366quPrDEqKkqjRo3S1atXVbp06RQf0j3s7/PmzZv1xRdfKCkpSQcOHFBwcHC6PyPWkBuPf27+f/KhDDyRq1evGj4+PsapU6cMwzCMkJAQw9vb24iMjDQCAgKMqKgowzAMIyoqynjuueeMv/76yzAMw2jZsqVx/PhxwzAMIykpyYiOjrZ8/9577xnLly83DMMw5s6da3z00UeW7f399d+/X7t2rTFs2LAc2OO849tvvzUGDBhgeX3z5k0jLCzMaN26tXHlyhXDMAwjJibGuHv37iPPwd+P7c8//2wMGjTIiI+PNwzDMHbs2GF0797dMAzDWLJkidG/f38jISHBiIuLMzp37pwrz0lax8UwjFxxbOLi4gwfHx8jISHB2LRpk9G9e3fjX//6l2EYhjFgwABjz549hmEYxokTJ4w+ffoYhmEYx48fN5o0aWL5XZs9e7bx1ltvpVp3fHy80bx5c8s6fvrpJ6N58+ZGfHy8ERYWZnTu3Nky799fP/ieYaT8/e3du7exfft2wzAMY+zYscb69esNwzAMs9lsvPPOO8aqVass87322mtGYmJi2icmC92v78aNG0bdunWNO3fuGIZhGLdv3zYSExONa9euGQ0aNDBOnjxpGIZhfPXVV0a3bt3SXe+D15m33nrLmD17tmEYyde4Jk2aWI5Ly5YtjfHjx1vm/fe//238+9//tryePn26MWvWLMMwDKNOnTqW8xcfH2/ExcWl2I/7OnbsaBw4cMAwDMO4d++ecfv27Uwdl8zw9vY2YmJiHvlzc/r0aaNx48bGmTNnLLXfr+n69euWdc2aNcuYMWOGYRhp/zzd96jjeb+eB+tL673Ro0cbS5cuNQwj5d+JDRs2GB988IFhNpsNwzCMZcuWGe+++65lvubNm6eo++8uXLhg+Pj4WF4vW7bM6NevnxEfH2/Ex8cbffv2NZYtW2YYhmEEBgYaEydOtGzn/jof/Hv2qN/dtWvXGrVq1TLOnTuXZj25jbe3t/Hll18ahmEYW7ZsMWrVqmW5LoSEhBgjRowwDOPh19mjR48aTZo0Ma5evWoYhmGMHz8+xfF+Gm3fvt144YUXUk3/448/MnRs2rVrZ3z33XeZ3q7ZbDaGDh1q+Pj4GMOGDTMWLVpk+RtoGIYxadIkY9q0aYZhJF9Ta9eubURGRhqG8X/XyDVr1hjTp083YmJijFatWhlnz57Nk+fz79fgvXv3GrVr17b8H/uw+UaPHm107tzZiI2Ntbz/qOth1apVjT/++MMwDMOYP3++5Zo0adIkY8GCBZbl7v+v8ihvvvmmERwcbBiGYZw/f96oVauW5Vr4qL/PD16bcovcfvxz8/+TD0OL7xM6ePCgqlatqgoVKkiSunfvrpkzZ+qPP/5QRESEBg0aZJnXZDLp3Llzql69eop1JCUl6b///a927dqlpKQk/fXXX8qXL1+O7octqly5sk6dOqUJEybIx8dHLVq00I4dOxQQECB3d3dJsrSemM3mDJ2D7du369ixY3rxxRclJd+7c+vWLUnJrYSdOnWSo6OjHB0d9cILL+jAgQM5tLcZl9ZxkZQrjk3+/Pn1j3/8QwcPHtSePXv0+uuva8aMGUpISNDhw4dVp04dSSm7OYeHh6t58+by8PCQJMs9qA86c+aMHB0d1ahRI0lS48aN5ejoqDNnzjz2sUzrGBw6dEiLFi2SJN29e1clSpSwvN+xY8cc7XZUqFAheXl5adSoUWratKlatGghFxcXHTx4UJUrV9azzz4rKbn73oQJExQTEyMXF5cMr3/v3r0KDAyUJHl4eKh58+YKDw+3dLe631opJR+bmJgY/e9//5OUfO9e5cqVJUkNGzZUYGCgWrZsqRYtWqhs2bJpbq9hw4aaOnWq2rRpo2bNmqXq1pUdHvVzs3//fjVr1kzlypWTJDk5OVk+ud64caM2bdqkxMRExcXFWeZ5lPSO55Pavn27fv/9d3Xu3FmSLJ+k39esWbNHtiQ8WGvnzp0t+9ulSxd9//33evnll/XDDz9o3bp1ltaWh60zvd/dOnXq5MqWl4dp166dJOmf//ynJKlly5aSpGrVqum7776T9PDr7L59+9SiRQsVL15cUvL/Elu3bs3R+nMbwzCssl07OzvNnz9fJ06c0M8//6zvv/9eCxcu1KZNm1SkSBF169ZNAwcO1IgRI7R161bVqVNHJUuWTLEOPz8/denSReXKlVPr1q3zdDf9+71uXFxcFBwcLFdX13SX8fPzU4ECBSyvH3U9LF++vKVFvVatWvrhhx8kSfXr19eMGTN0584dNWjQQA0bNkx3u+Hh4ZYej2XLlrVct6X0/z7nVrn5+Ofm/ycfhuCbTQzDSDXAwcNs2rRJv/zyi5YtWyYXFxctWLBAZ8+elSTZ29srKSnJMm98fHx2lWxzypYtq9DQUIWFhWnXrl2aPXv2Q+8JfdQ5+DvDMNS1a1e99dZb2Vx99knruGzatOmh8+f0sWnYsKHCwsJ08OBBBQUFyc3NTZs3b1blypUt3d22bdum2bNnP9F2/s7e3j7FP1mP+3tmGIbmz5//0OD29z9EOcHe3l5fffWVDhw4oLCwMHXp0iVHBqW67+/7axiGxo8fn+IfkfvmzZunw4cPKywsTH379lVQUFCaXT3Hjh2r48ePKywsTG+99Zb69++vl156KVv34XHs379fK1as0MqVK1WsWDFt2rRJX3311ROt8+8/o0/y8zl06FB169Ytzffv/3OSW+S2etJz//pkZ2eXouuenZ2d7t27Z62y8ixvb2+dP39eN2/etHQ7lqTffvtNlSpVSjX/iy++qISEBBUsWFDLly9X1apVdejQIbVu3fqxt+/t7a1evXqpffv22rdvn9q0aaPKlSvLw8NDu3bt0tq1a9WvX79UyxYsWFC1atXSzJkzLd0986q07h1Nz9+v/eldDx/2u9K2bVvVqlVLP/30kz777DOtXbvWcmvH40jv73NulZuPf27/fzItjOr8hGrVqqUjR45YTtzq1aslJX/ie+7cOYWFhVnmPXToUJqfYN6+fVtFixaVi4uLbt++rdDQUMt7zzzzjP744w8lJSUpJiZGO3bsSLOO+8vi/1y+fFn29vZq3bq1xowZo+joaFWtWlUbN27UtWvXJEmxsbGKj49/5Dn4O19fX23cuFGXL1+WlPzp1e+//y4pObBt3LhR9+7d0927dx+6DmtL67jcvHlTLVq0yBXHpmHDhlq3bp1KliwpJycnNWrUSMHBwZbAFBUVpYSEBJUpU0aS1KBBA+3cuVNXr16VJH311Vdq3LhxqvWWL19eiYmJlt/JvXv36t69eypfvrzKli2rCxcu6K+//pJhGClGTnRxccnwoCS+vr4KCQmxjKgYHR2tCxcuZGjZ7BATE6Po6Gj5+Pho+PDh8vb21smTJ1WrVi0dO3ZMp06dkpR8L03VqlUz1dorSY0aNbL8Ab169ap27tz50E/lfX19tXjxYt29e9dS26lTp3Tv3j1duHBBNWrU0ODBg9WkSRPLQDIFCxZMcV07ffq0KlWqpH79+umFF17Q4cOHM31MMutRPzdNmjTRrl27LNf/hIQExcTE6NatW3JxcVGRIkWUkJCgtWvXZmhbjzqeXl5elv198B+LggULZuhn1NfXV8uXL9dff/1lqffYsWMZqi2tWjds2KDExEQlJiZqw4YNlt+7li1bauHChZa/d9HR0ZJS/53K6O+uLXnYddbHx0c7d+60jGK+Zs0aa5aZK5QpU0Z+fn4KCgqyfNhz4sQJLViwQG+++Waq+VevXq2NGzdq+fLlkpJHYP7qq6+0Z88eyzwXLlyw9Dp5mKioKP3666+W15cvX1Z0dLTlb46U3EsmODhYZ8+efegH6oMGDdKwYcPSDOlPk8e9Hp47d07u7u7q0qWL3njjjQxd7xs2bGhZ/4ULF7R3717Le7nt73NOyc7jn9v/n0wLLb5PyM3NTZMmTdKQIUOUL18+y+BWrq6umj9/vmbMmKEpU6YoMTFRZcuW1YIFC1KMlCkldwfctm2b/Pz85Obmprp161ou8s8//7y2bNmidu3aqVSpUpYuVA9q1KiR/vvf/+qFF16Qj48Pg1speUTHjz/+WFJyd/LBgwerY8eOunv3rvr37y+TySQnJyctWLDgkefg7+rXr6+3335bQ4cOldlsVmJiovz8/FStWjW99NJLOn78uNq3b6+iRYuqevXqVnsUy6OkdVxKlCihEiVKaPDgwVY/NjVr1tSNGzf08ssvS0r+2Z41a5YlAGzbtk2+vr6W+b29vTVy5EgNGDBAUvInkBMnTky1XicnJ82dOzfFIEVz5syRk5OTSpQoof79+6tLly4qXry46tevr5MnT0pKHrSmfPny8vf3V4UKFVINbvV3Y8eO1YwZMxQQECCTySRHR0eNHTvWap8wx8TEaNiwYbp7964Mw1DVqlXVpk0bOTs7a/r06Ro5cqTu3bunYsWKacaMGZKSj+/27dszNFr1Bx98oHHjxqljx46SpJEjR+of//hHmvMOHjxY8+bNU7du3SwjBr/55psqW7asAgMDdfv2bZlMJnl6eloeHdK3b1+NHTtW+fLl08cff6zZs2fr3Llzsre3l6ur62ONqJ1Zj/q5KVeunCZNmqR33nnHMurwRx99pOeee05ff/212rZtq6JFi6pevXoZ+qftUcdzzJgxGjdunAoVKiQ/P78Uyw0YMEB9+/ZVvnz5Ug1u9XedOnXSzZs31bt3b0nJn6r37NnT0uU8M7p3767z589buk03bdrU0vo+ZswYTZkyRf7+/rK3t7f8TWrdurU2bNiggIAAy+BWGfndtSUNGjRI8zpbuXJlDRkyRD179pSLi4uaNWtm7VJzhfHjx2vWrFlq3769HB0d5ezsrPfff18+Pj6Skh8n5+vrm2b4rFy5shYsWKDZs2dr3Lhxyp8/v4oWLWp59MnDlr13756Cg4N18eJF5cuXT0lJSXr77bct3UElyd/fX9OmTdNLL72U5sA8kvTss89abiexJQEBAQoJCclwN+HHvR5u3bpVmzZtkqOjo0wmk8aOHSvp0X+j3n//fY0aNUqhoaEqU6ZMisEPM/r3OTN/A63B2sf/73L7/5NpMRnWuokCAB7Dq6++qnfeeUfVqlWzdikAAADIIwi+AAAAAACbxj2+AAAAAACbRvAFAAAAANg0gi8AAAAAwKYRfAEAAAAANo3gCwBAHnX69GkFBASodu3aWrJkSbrzBwcHa+TIkTlQGQAAuQvBFwCAdPj6+mrPnj3WLiOVzz//XA0aNNCvv/6qvn37Zum6AwMDNXv27CxdpzW3AwB4uhF8AQDIoy5duqR//OMf1i4DAIBcj+ALAMAjvPfee7p06ZKGDBmi2rVr67PPPtPgwYO1dOnSFPN17NhR3333nSSpUqVKWrJkiVq1aqUGDRpo2rRpSkpKssy7Zs0atWvXTvXr19err76qixcvPnT727ZtU4cOHVSvXj316dNHp06dkiT17dtX4eHhmjhxomrXrq0zZ86kWvbChQvq3bu3ateurf79++vGjRsp3h8+fLiaNGmiunXrqlevXjp58qQkadWqVdq0aZMWLlyo2rVra8iQIZKkkJAQtW7dWrVr11b79u0t+ytJ586dU+/evVW3bl01aNBAb7/9tuW9U6dOqX///vLx8VHbtm21ZcuWR24HAIAsZwAAgEdq2bKl8dNPP1leb9682ejWrZvl9dGjRw0fHx8jPj7eMAzD8Pb2Nnr37m3cuHHDuHjxotGmTRvjq6++MgzDML777jujdevWxp9//mkkJiYa//73v43u3bunud3Tp08bNWvWNHbv3m0kJCQYISEhRuvWrS3b6d27t2W9aXnppZeMKVOmGPHx8ca+ffuMWrVqGSNGjLC8v3r1auP27dtGfHy88eGHHxovvPCC5b3Ro0cbs2bNSrG+LVu2GJcvXzbMZrOxefNmo2bNmkZUVJRhGIbxzjvvGPPnzzfMZrNx9+5d4+effzYMwzBiY2ONZs2aGWvWrDESExONP/74w/Dx8TFOnjz50O0AAJDVaPEFACCTWrVqpbNnz+rs2bOSpI0bN6pdu3ZycnKyzDNo0CAVKVJEpUqVUt++fRUaGipJWrlypQYPHqyKFSvKwcFBQ4YM0dGjR9Ns9d2yZYuaN2+uJk2ayNHRUa+++qru3r2rX3/9Nd0aL126pMOHD+utt96Sk5OT6tevL19f3xTzdOvWTS4uLnJyctKwYcN07Ngx3b59+6HrbNeunUqUKCE7Ozu1b99ezzzzjA4dOiRJcnBw0KVLl3TlyhU5OzurXr16kqQdO3aodOnS6tq1qxwcHFS1alW1bdtW33zzTbr7AABAViH4AgCQSc7OzmrXrp2+/vprJSUlKTQ0VAEBASnm8fT0tHxfunRpXblyRVJyIJ0yZYrq1aunevXqycfHR4ZhKCoqKtV2rly5olKlSlle29nZydPTM81501rW1dVVBQoUsEz7+7rMZrNmzpyp1q1bq06dOpZQ/GB36L/bsGGDAgICLLWfPHnSMv97770nwzDUrVs3dejQQWvWrJEkXbx4UYcOHbIsU69ePW3atElXr15Ndx8AAMgqDtYuAACAvKhz584aNWqU6tatq/z586t27dop3o+MjLQMPHXp0iV5eHhISg7EQ4YM0QsvvJDuNjw8PHTixAnLa8MwFBkZqRIlSqS7rLu7u27duqW4uDhL+L106ZJMJpMkadOmTdq2bZsWLVqkMmXK6Pbt26pfv74Mw5Aky3z3Xbx4UR988IEWL16s2rVry97ePkXYd3d314cffihJ2r9/v/r376/69evL09NT9evX16JFi9Ks88HtAACQHWjxBQAgHcWLF9eFCxdSTKtdu7bs7Oz00UcfpRliFy5cqL/++kuRkZFasmSJ2rdvL0nq0aOHQkJCLANJ3b59W1u3bk1zu+3atdPOnTu1d+9eJSYm6r///a+cnJxShey0lC5dWtWqVVNwcLASEhK0f/9+/fDDD5b3Y2Nj5eTkpKJFi+rOnTuaNWtWiuXd3NwUERFheX3nzh2ZTCYVK1ZMkrR27VrLPkjS1q1bdfnyZUlS4cKFZTKZZGdnpxYtWujs2bPasGGDEhMTlZiYqEOHDlkG6XpwOwAAZAeCLwAA6Rg8eLD+85//qF69elq4cKFlekBAgE6cOJGqm7OUfB9wly5d1KlTJ7Vo0ULdunWTJD3//PMaOHCg3n33XdWpU0f+/v7atWtXmtutUKGCZsyYoUmTJqlhw4b64YcftGDBghT3Ej/Kxx9/rIMHD6pBgwb697//rU6dOlne69Spk0qVKqXnnntOHTp0UK1atVIs261bN/3555+qV6+eXn/9dT377LMaMGCAevToocaNG+vEiROqU6eOZf7Dhw/rxRdfVO3atTV06FC9//77Klu2rFxcXLRw4UJt2bJFzz33nJo2baqZM2cqISEhze0AAJAdTMb9Pk0AACBTNmzYoFWrVmnFihUppleqVEnffvutnnnmGStVBgAA/o4WXwAAHsOdO3e0fPlyde/e3dqlAACAdBB8AQDIpB9//FGNGjWSm5ub/P39rV0OAABIB12dAQAAAAA2jRZfAAAAAIBNI/gCAAAAAGwawRcAAAAAYNMIvgAAAAAAm0bwBQAAAADYtP8HMKT9O61CIWUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest Lin. Reg. Score:  0.6009445687298036 with  O.-C. SVM\n",
      "Highest Log. Reg. (one vs. rest) Score:  0.442467436716638 with  P.Trans scaled\n",
      "Highest Log. Reg. (multinomial) Score:  0.3893872368313263 with  P.Trans scaled\n",
      "Highest Ordered Log. Reg. Score:  0.6026936026936026 with  Iso. forests\n"
     ]
    }
   ],
   "source": [
    "# choose models\n",
    "#from warnings import filterwarnings\n",
    "#filterwarnings('ignore')\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from mord import LogisticAT\n",
    "\n",
    "model_linear = LinearRegression()\n",
    "model_1vR = LogisticRegression(multi_class='ovr',\n",
    "    class_weight='balanced')\n",
    "model_multi = LogisticRegression(multi_class='multinomial',\n",
    "    solver='lbfgs',\n",
    "    class_weight='balanced',max_iter=2000) #max_iter manuell auf 200 gesetzt, davor wurde default Wert genutzt\n",
    "model_ordinal = LogisticAT(alpha=0)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import make_scorer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "reds_x = [x_red, x_red_scaled,x_red_mcd_scaled,x_red_iso,x_red_lof, x_red_mcd,x_red_ocs,x_red_pt,x_red_pt_scaled]\n",
    "reds_y = [y_red,y_red,y_red_mcd,y_red_iso,y_red_lof,y_red_mcd,y_red_ocs,y_red,y_red]\n",
    "\n",
    "whites_x =[x_white,x_white_scaled,x_white_mcd_scaled,x_white_lof,x_white_mcd,x_white_mcd_scaled,x_white_ocs,x_white_mcd_scaled_pt]\n",
    "whites_y =[y_white,y_white,y_white_mcd,y_white_lof,y_white_mcd,y_white_mcd,y_white_ocs,y_white_mcd]\n",
    "\n",
    "desc = ['default','scaled','scaled w/o outlier','Iso. forests','local outlier foctor', 'mcd', 'O.-C. SVM',\n",
    "        'P.Trans. def.','P.Trans scaled', 'P.trans. scaled w/o outlier']\n",
    "desc_w = ['default','scaled','scaled w/o outlier','Iso. forests','local outlier foctor', 'mcd', 'O.-C. SVM','P.trans. scaled w/o outlier']\n",
    "from sklearn.utils.testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "my_list_lin = []\n",
    "my_list_1vR = []\n",
    "my_list_multi= []\n",
    "my_list_ord=[]\n",
    "my_list_desc=[]\n",
    "my_list_type=['Linear Regression', 'Logistic Regression one vs. rest','Logistic Regression multinomial','Ordered Logistic Regression']\n",
    "def make_all_regression(x,y):\n",
    "    i=0\n",
    "    features = x  #alle ausser quality\n",
    "    target = y.values.ravel()\n",
    "\n",
    "    MAE = make_scorer(mean_absolute_error)\n",
    "    folds = 5\n",
    "\n",
    "    MAE_linear = cross_val_score(model_linear,\n",
    "        features,\n",
    "        target,\n",
    "        cv=folds,\n",
    "        scoring=MAE)\n",
    "    MAE_1vR = cross_val_score(model_1vR,\n",
    "        features,\n",
    "        target,\n",
    "        cv=folds,\n",
    "        scoring=MAE)\n",
    "    MAE_multi = cross_val_score(model_multi,\n",
    "        features,\n",
    "        target,\n",
    "        cv=folds,\n",
    "        scoring=MAE)\n",
    "    MAE_ordinal = cross_val_score(model_ordinal,\n",
    "        features,\n",
    "        target,\n",
    "        cv=folds,\n",
    "        scoring=MAE)\n",
    "\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "    def acc_fun(target_true, target_fit):\n",
    "        target_fit = np.round(target_fit)\n",
    "        target_fit.astype('int')\n",
    "        return accuracy_score(target_true, target_fit)\n",
    "\n",
    "    acc = make_scorer(acc_fun)\n",
    "    folds = 5\n",
    "    print('Accuracy:' )\n",
    "    acc_linear = cross_val_score(model_linear,\n",
    "        features,\n",
    "        target,\n",
    "        cv=folds,\n",
    "        scoring=acc)\n",
    "    print('Linear regression: ', np.mean(acc_linear))\n",
    "    acc_1vR = cross_val_score(model_1vR,\n",
    "        features,\n",
    "        target,\n",
    "        cv=folds,\n",
    "        scoring=acc)\n",
    "    print('Logistic regression (one vs. rest): ', np.mean(acc_1vR))\n",
    "    acc_multi = cross_val_score(model_multi,\n",
    "        features,\n",
    "        target,\n",
    "        cv=folds,\n",
    "        scoring=acc)\n",
    "    print('Logistic regression (multinomial): ', np.mean(acc_multi))\n",
    "    acc_ordinal = cross_val_score(model_ordinal,\n",
    "        features,\n",
    "        target,\n",
    "        cv=folds,\n",
    "        scoring=acc)\n",
    "    print('Ordered logistic regression: ', np.mean(acc_ordinal))\n",
    "    \n",
    "    my_list_lin.append(np.mean(acc_linear))\n",
    "    my_list_1vR.append(np.mean(acc_1vR))\n",
    "    my_list_multi.append(np.mean(acc_multi))\n",
    "    my_list_ord.append(np.mean(acc_ordinal))\n",
    "    \n",
    "    return acc_linear, acc_1vR, acc_multi,acc_ordinal\n",
    "\n",
    "for i in range(0,9): #range(0,9) bei rot; range(0,8) bei white\n",
    "    print(desc[i])\n",
    "    my_list_desc.append(desc[i])\n",
    "    make_all_regression(reds_x[i], reds_y[i])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,8))\n",
    "ax.scatter(my_list_desc, my_list_lin,color='r')\n",
    "ax.scatter(my_list_desc, my_list_1vR,color='b')\n",
    "ax.scatter(my_list_desc, my_list_multi,color='g')\n",
    "ax.scatter(my_list_desc, my_list_ord,color='c')\n",
    "ax.set_ylabel('regression score')\n",
    "ax.set_xlabel('type of dataset')\n",
    "ax.legend(my_list_type)\n",
    "#plt.plot(my_list_i, my_list_reg)\n",
    "plt.show()   \n",
    "\n",
    "import operator\n",
    "index, value = max(enumerate(my_list_lin), key=operator.itemgetter(1))\n",
    "print(\"Highest Lin. Reg. Score: \",value, \"with \",my_list_desc[index])\n",
    "\n",
    "index, value = max(enumerate(my_list_1vR), key=operator.itemgetter(1))\n",
    "print(\"Highest Log. Reg. (one vs. rest) Score: \",value, \"with \",my_list_desc[index])\n",
    "\n",
    "index, value = max(enumerate(my_list_multi), key=operator.itemgetter(1))\n",
    "print(\"Highest Log. Reg. (multinomial) Score: \",value, \"with \",my_list_desc[index])\n",
    "\n",
    "index, value = max(enumerate(my_list_ord), key=operator.itemgetter(1))\n",
    "print(\"Highest Ordered Log. Reg. Score: \",value, \"with \",my_list_desc[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "Linear regression:  0.5888998115835176\n",
      "Logistic regression (one vs. rest):  0.429055050380929\n",
      "Logistic regression (multinomial):  0.3644773490620136\n",
      "Ordered logistic regression:  0.5940157286802654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.58146965, 0.56230032, 0.59105431, 0.58146965, 0.62820513]),\n",
       " array([0.42811502, 0.39936102, 0.46645367, 0.38019169, 0.47115385]),\n",
       " array([0.39936102, 0.33226837, 0.35463259, 0.32907348, 0.40705128]),\n",
       " array([0.58146965, 0.57188498, 0.60702875, 0.57507987, 0.63461538]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_red_real_new1=x_red_scaled[['citric acid','residual sugar','chlorides','free sulfur dioxide',\n",
    "                              'total sulfur dioxide','pH','sulphates','magnesium','alcohol']]\n",
    "\n",
    "x_red_real_new2=x_red_scaled[['residual sugar','pH','magnesium']]\n",
    "\n",
    "make_all_regression(x_red_scaled, y_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "Linear regression:  0.6060606060606061\n",
      "Logistic regression (one vs. rest):  0.44713804713804717\n",
      "Logistic regression (multinomial):  0.3569023569023569\n",
      "Ordered logistic regression:  0.6026936026936027\n",
      "Accuracy:\n",
      "Linear regression:  0.6094276094276094\n",
      "Logistic regression (one vs. rest):  0.4316498316498317\n",
      "Logistic regression (multinomial):  0.36026936026936024\n",
      "Ordered logistic regression:  0.6020202020202021\n",
      "Accuracy:\n",
      "Linear regression:  0.6074074074074074\n",
      "Logistic regression (one vs. rest):  0.44377104377104376\n",
      "Logistic regression (multinomial):  0.3602693602693603\n",
      "Ordered logistic regression:  0.6013468013468013\n",
      "Accuracy:\n",
      "Linear regression:  0.6080808080808081\n",
      "Logistic regression (one vs. rest):  0.43367003367003365\n",
      "Logistic regression (multinomial):  0.3595959595959596\n",
      "Ordered logistic regression:  0.6\n",
      "Accuracy:\n",
      "Linear regression:  0.6080808080808081\n",
      "Logistic regression (one vs. rest):  0.43367003367003365\n",
      "Logistic regression (multinomial):  0.3595959595959596\n",
      "Ordered logistic regression:  0.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.58922559, 0.61952862, 0.58922559, 0.5993266 , 0.64309764]),\n",
       " array([0.44781145, 0.41077441, 0.45454545, 0.4006734 , 0.45454545]),\n",
       " array([0.40740741, 0.32659933, 0.32659933, 0.35690236, 0.38047138]),\n",
       " array([0.6026936 , 0.58249158, 0.60606061, 0.58585859, 0.62289562]))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_red_end_new = x_red_iso[['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'total sulfur dioxide', 'pH', 'sulphates', 'alcohol', 'lightness']]\n",
    "#print(x_red_end_new)\n",
    "make_all_regression(x_red_end_new, y_red_iso)\n",
    "x_red_end_new2 = x_red_iso[['fixed acidity', 'volatile acidity', 'citric acid', 'chlorides', 'total sulfur dioxide', 'sulphates', 'magnesium', 'alcohol', 'lightness']]\n",
    "#print(x_red_end_new2)\n",
    "make_all_regression(x_red_end_new2, y_red_iso)\n",
    "x_red_end_new3 = x_red_iso[['fixed acidity', 'volatile acidity', 'citric acid', 'chlorides', 'total sulfur dioxide', 'pH', 'sulphates', 'alcohol', 'lightness']]\n",
    "#print(x_red_end_new3)\n",
    "make_all_regression(x_red_end_new3, y_red_iso)\n",
    "x_red_end_new4 = x_red_iso[['fixed acidity', 'volatile acidity', 'citric acid', 'chlorides', 'total sulfur dioxide', 'pH', 'sulphates', 'magnesium', 'alcohol', 'lightness']]\n",
    "#print(x_red_end_new4)\n",
    "make_all_regression(x_red_end_new4, y_red_iso)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'pH', 'sulphates', 'magnesium', 'alcohol']\n",
      "Accuracy:\n",
      "Linear regression:  0.49970405389533024\n",
      "Logistic regression (one vs. rest):  0.2524023860261423\n",
      "Logistic regression (multinomial):  0.20691792372099266\n",
      "Ordered logistic regression:  0.4986794637313959\n",
      "Accuracy:\n",
      "Linear regression:  0.4919152809705187\n",
      "Logistic regression (one vs. rest):  0.26326199305334164\n",
      "Logistic regression (multinomial):  0.22003267781935332\n",
      "Ordered logistic regression:  0.4935563031696226\n",
      "Accuracy:\n",
      "Linear regression:  0.49970405389533024\n",
      "Logistic regression (one vs. rest):  0.2692014698726446\n",
      "Logistic regression (multinomial):  0.22023423997852237\n",
      "Ordered logistic regression:  0.49888417202208163\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.44421699, 0.48258197, 0.49590164, 0.5307377 , 0.54508197]),\n",
       " array([0.29682702, 0.2295082 , 0.31352459, 0.28381148, 0.22233607]),\n",
       " array([0.2569089 , 0.17418033, 0.23463115, 0.26741803, 0.16803279]),\n",
       " array([0.44524053, 0.4795082 , 0.49897541, 0.52766393, 0.54303279]))"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_white_end_new = x_white.drop([\"density\", \"lightness\"], axis=1)\n",
    "#print(x_red_end_new4)\n",
    "print(x_white_end_new.columns.values.tolist())\n",
    "make_all_regression(x_white_end_new, y_white)\n",
    "#print(x_white_end_new.describe())\n",
    "\n",
    "x_white_end_new2 = x_white.drop([\"density\", \"lightness\", 'citric acid','fixed acidity','total sulfur dioxide'], axis=1)\n",
    "#print(x_red_end_new4)\n",
    "make_all_regression(x_white_end_new2, y_white)\n",
    "#print(x_white_end_new.describe())\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mms = MinMaxScaler()\n",
    "\n",
    "x_white_end_new[['total sulfur dioxide','free sulfur dioxide']] = mms.fit_transform(x_white_end_new[['total sulfur dioxide','free sulfur dioxide']])\n",
    "#print(x_white_end_new.describe())\n",
    "make_all_regression(x_white_end_new, y_white)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "Linear regression:  0.49151089819957383\n",
      "Logistic regression (one vs. rest):  0.26182463043441784\n",
      "Logistic regression (multinomial):  0.21244861318522745\n",
      "Ordered logistic regression:  0.498476433377519\n"
     ]
    }
   ],
   "source": [
    "x_red_end_new5 = x_white[['residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'magnesium', 'alcohol', 'lightness']]\n",
    "#print(x_red_end_new5)\n",
    "make_all_regression(x_red_end_new5, y_white)\n",
    "\n",
    "x_red_end_new5[['total sulfur dioxide','free sulfur dioxide']] = mms.fit_transform(x_red_end_new5[['total sulfur dioxide','free sulfur dioxide']])\n",
    "#print(x_white_end_new.describe())\n",
    "#make_all_regression(x_red_end_new5, y_white)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
